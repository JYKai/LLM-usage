{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0f00366-5f5a-404c-8bc4-81207e8da920",
   "metadata": {},
   "source": [
    "# Text2SQL : 성능 평가 파이프라인 준비하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235610e-0e45-4420-8bf3-4a51954e452e",
   "metadata": {},
   "source": [
    "## SQL 생성 프롬프트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f279bf6-53b2-4087-a2b0-d2375b347b9f",
   "metadata": {},
   "source": [
    "**SQL 프롬프트**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "094474e1-575d-4554-95cd-cee2b62efeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prompt(ddl, question, query=''):\n",
    "    prompt = f\"\"\"당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\n",
    "### DDL:\n",
    "{ddl}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### SQL:\n",
    "{query}\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d63b6bd-d643-49c6-b705-c98309cf16e8",
   "metadata": {},
   "source": [
    "## GPT-4 평가 프롬프트와 코드 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c197496-f665-4c0a-ab69-74630a9dd5db",
   "metadata": {},
   "source": [
    "**평가를 위한 요청 jsonl 작성 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a86ab18-489d-40b1-80e4-7e533253019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3371c2a7-222b-44f6-8553-fd5be48606ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_requests_for_gpt_evaluation(df, filename, dir='requests'):\n",
    "    if not Path(dir).exists():\n",
    "        Path(dir).mkdir(parents=True)\n",
    "    prompts = []\n",
    "    for idx, row in df.iterrows():\n",
    "        prompts.append(\"\"\"Based on below DDL and Question, evaluate gen_sql can resolve Question. If gen_sql and gt_sql do equal job, return \"yes\" else \"no\". Output Json Format: {\"resolve_yn\": \"\"}\"\"\" + f\"\"\"\n",
    "\n",
    "DDL: {row['context']}\n",
    "Question: {row['question']}\n",
    "gt_sql: {row['answer']}\n",
    "gen_sql: {row['gen_sql']}\"\"\"\n",
    ")\n",
    "\n",
    "    jobs = [{\"model\": \"gpt-4-turbo\", \"response_format\": {\"type\": \"json_object\"}, \"messages\": [{\"role\": \"system\", \"content\": prompt}]} for prompt in prompts]\n",
    "    with open(Path(dir, filename), \"w\") as f:\n",
    "        for job in jobs:\n",
    "            json_string = json.dumps(job)\n",
    "            f.write(json_string + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca35696-0d83-4c29-8044-e10a972a3e8a",
   "metadata": {},
   "source": [
    "**비동기 요청 명령**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ab6f9e9-2051-49e0-8735-62c8db55f9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a5ce702-a038-4483-8d68-3bc15acc84e8",
   "metadata": {},
   "source": [
    "```python\n",
    "python api_request_parallel_processor.py \\\n",
    "    --requests_filepath {요청 파일 경로} \\\n",
    "    --save_filepath {생성할 결과 파일 경로} \\\n",
    "    --request_url https://api.openai.com/v1/chat/completions \\\n",
    "    --max_requests_per_minute 300 \\\n",
    "    --max_tokens_per_minute 100000 \\\n",
    "    --token_encoding_name cl100k_base \\\n",
    "    --max_attempts 5 \\\n",
    "    --logging_level 20\n",
    "```\n",
    "- --requests_filepath {요청 파일 경로}:\n",
    "    - 요청 파일의 경로를 지정합니다. 이 파일은 미리 준비된 API 요청을 포함하고 있으며, 이 파일을 기반으로 OpenAI API로 병렬 요청을 보냅니다. 이 요청 파일은 앞서 설명한 make_requests_for_gpt_evaluation 함수에서 생성한 파일이 될 것입니다.\n",
    "- --save_filepath {생성할 결과 파일 경로}:\n",
    "    - API 응답 결과를 저장할 파일 경로를 지정합니다. 각 요청에 대한 응답이 JSON 형식으로 이 파일에 기록됩니다.\n",
    "- --request_url https://api.openai.com/v1/chat/completions:\n",
    "    - GPT API의 요청 URL입니다. 여기서는 GPT-4 API를 사용하고 있으며, chat/completions 엔드포인트는 채팅 기반 모델의 응답을 받기 위한 엔드포인트입니다.\n",
    "- --max_requests_per_minute 300:\n",
    "    - 분당 최대 요청 수를 제한합니다. API 서버의 요청 속도를 제어하여, 과도한 요청으로 인한 속도 제한(rate limiting)을 방지합니다. 이 예시에서는 분당 최대 300개의 요청을 허용하고 있습니다.\n",
    "- --max_tokens_per_minute 100000:\n",
    "    - 분당 최대 토큰 수를 제한합니다. OpenAI의 API 사용 시 응답의 토큰 수에 따라 비용이 발생하므로, 토큰 사용량을 제어하여 효율적인 요청을 보낼 수 있습니다. 여기서는 분당 최대 100,000 토큰을 허용하고 있습니다.\n",
    "- --token_encoding_name cl100k_base:\n",
    "    - 토큰 인코딩 방식을 지정합니다. OpenAI의 모델에서 사용하는 토큰화 알고리즘을 명시하며, 여기서는 cl100k_base라는 인코딩 방식을 사용하고 있습니다. 이 방식은 GPT-4와 호환되는 인코딩 방식입니다.\n",
    "- --max_attempts 5:\n",
    "    - 최대 재시도 횟수를 지정합니다. 네트워크 오류나 API 오류로 인해 요청이 실패할 경우, 최대 5회까지 재시도를 허용하여 요청의 성공 가능성을 높입니다.\n",
    "- --logging_level 20:\n",
    "    - 로그 레벨을 설정합니다. 20은 INFO 수준의 로그를 의미하며, 이 설정은 진행 상황 및 오류 메시지를 적절한 수준으로 출력하게 됩니다.\n",
    "    - 주요 로그 레벨:\n",
    "        - 10: DEBUG (상세한 로그)\n",
    "        - 20: INFO (기본적인 정보 출력)\n",
    "        - 30: WARNING (경고 메시지)\n",
    "        - 40: ERROR (에러 메시지)\n",
    "        - 50: CRITICAL (심각한 에러 메시지)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52bad48-0598-4513-9977-97a3befdd12a",
   "metadata": {},
   "source": [
    "**결과 jsonl 파일을 csv로 변환하는 함수**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59044456-bbee-4a78-8272-c09960d511cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_jsonl_to_csv(input_file, output_file, prompt_column=\"prompt\", response_column=\"response\"):\n",
    "    prompts = []\n",
    "    responses = []\n",
    "    with open(input_file, 'r') as json_file:\n",
    "        for data in json_file:\n",
    "            prompts.append(json.loads(data)[0]['messages'][0]['content'])\n",
    "            responses.append(json.loads(data)[1]['choices'][0]['message']['content'])\n",
    "\n",
    "    df = pd.DataFrame({prompt_column: prompts, response_column: responses})\n",
    "    df.to_csv(output_file, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff19378-330a-4142-9803-94202ff4f1d9",
   "metadata": {},
   "source": [
    "# 미세 조정 수행하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad6e093-d4fd-4fa6-bba0-fee91a2b0d2b",
   "metadata": {},
   "source": [
    "## 기초 모델 평가하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd641ee-5b4c-418c-97c6-3bf4fb4c0d25",
   "metadata": {},
   "source": [
    "**기초 모델로 생성하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "23e1f0fa-60c5-4c74-9dbe-17ea19291f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-22 05:44:38.005229: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-22 05:44:38.013392: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-22 05:44:38.022798: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-22 05:44:38.025581: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-22 05:44:38.032980: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-22 05:44:38.449724: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0972c9ce-90a9-4e32-8720-0d998c95cc6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_inference_pipeline(model_id):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "    pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "    return pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645d761-6661-440b-9ba7-61fa436b6074",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = 'beomi/Yi-Ko-6B'\n",
    "hf_pipe = make_inference_pipeline(model_id)\n",
    "\n",
    "example = \"\"\"당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\n",
    "\n",
    "### DDL:\n",
    "CREATE TABLE players (\n",
    "    player_id INT PRIMARY KEY AUTO_INCREMENT,\n",
    "    username VARCHAR(255) UNIQUE NOT NULL,\n",
    "    email VARCHAR(255) UNIQUE NOT NULL,\n",
    "    password_hash VARCHAR(255) NOT NULL,\n",
    "    date_joined DATETIME NOT NULL,\n",
    "    last_login DATETIME\n",
    ");\n",
    "\n",
    "### Question:\n",
    "사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.\n",
    "\n",
    "### SQL:\n",
    "\"\"\"\n",
    "\n",
    "hf_pipe(example, do_sample=False, return_full_text=False, max_length=1024, truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "20a4ca3f-9468-4657-a9d1-efa33abb5c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e9772d949249a69b69a80a85e894dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'beomi/Yi-Ko-6B'\n",
    "hf_pipe = make_inference_pipeline(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "916c3315-804a-4d41-91be-d092eb13d39d",
   "metadata": {},
   "source": [
    "**기초 모델 성능 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b490c83a-7262-4723-80ba-5f12efbf8c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2488051a-f517-4315-9129-e3d944cd7a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 불러오기\n",
    "df = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")['test']\n",
    "df = df.to_pandas()\n",
    "for idx, row in df.iterrows():\n",
    "    prompt = make_prompt(row['context'], row['question'])\n",
    "    df.loc[idx, 'prompt'] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a57e6954-fe4e-4cf9-96d3-5004151b9547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>각 보상 아이템별로 보상 경험치의 합을 구해줘</td>\n",
       "      <td>SELECT reward_items, SUM(reward_experience) AS...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE players (\\n  player_id INT PRIMAR...</td>\n",
       "      <td>사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.</td>\n",
       "      <td>SELECT COUNT(*) FROM players WHERE username LI...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?</td>\n",
       "      <td>SELECT q.name, q.reward_experience FROM quests...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가</td>\n",
       "      <td>SELECT name FROM characters WHERE experience &gt;...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.</td>\n",
       "      <td>SELECT C.name, ST.skill_name FROM characters A...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   db_id                                            context  \\\n",
       "0      1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "1      1  CREATE TABLE players (\\n  player_id INT PRIMAR...   \n",
       "2      1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "3      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "4      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "\n",
       "                                         question  \\\n",
       "0                       각 보상 아이템별로 보상 경험치의 합을 구해줘   \n",
       "1          사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.   \n",
       "2        퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?   \n",
       "3        경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가   \n",
       "4  레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.   \n",
       "\n",
       "                                              answer  \\\n",
       "0  SELECT reward_items, SUM(reward_experience) AS...   \n",
       "1  SELECT COUNT(*) FROM players WHERE username LI...   \n",
       "2  SELECT q.name, q.reward_experience FROM quests...   \n",
       "3  SELECT name FROM characters WHERE experience >...   \n",
       "4  SELECT C.name, ST.skill_name FROM characters A...   \n",
       "\n",
       "                                              prompt  \n",
       "0  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "1  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "2  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "3  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "4  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a702330-15f6-4208-8eb2-c9d33c84f12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql 생성\n",
    "gen_sqls = hf_pipe(df['prompt'].tolist(), do_sample=False, return_full_text=False, max_length=1024, truncation=True)\n",
    "gen_sqls = [x[0]['generated_text'] for x in gen_sqls]\n",
    "df['gen_sql'] = gen_sqls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71993a31-599f-4782-ab44-2cbb3313df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가를 위한 requests.jsonl 생성\n",
    "eval_filepath = \"text2sql_evalutation.jsonl\"\n",
    "make_requests_for_gpt_evaluation(df, eval_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027a690-6150-438b-af8f-19eb738585ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 평가 수행\n",
    "!python3 api_request_parallel_processor.py \\\n",
    "    --requests_filepath requests/{eval_filepath} \\\n",
    "    --save_filepath results/{eval_filepath} \\\n",
    "    --request_url https://api.openai.com/v1/chat/completions \\\n",
    "    --max_requests_per_minute 2500 \\\n",
    "    --max_tokens_per_minute 100000 \\\n",
    "    --token_encoding_name cl100k_base \\\n",
    "    --max_attempts 5 \\\n",
    "    --logging_level 20 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "913182bf-1e1c-4f03-8c84-83e215992ecf",
   "metadata": {},
   "source": [
    "- 현재 무료 크레딧이 없으므로 API 사용 불가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77194dd4-fb04-4712-95b2-7a75e63bfb5f",
   "metadata": {},
   "source": [
    "## 미세 조정 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f241807-72fd-488a-8831-13bad2dcf5a9",
   "metadata": {},
   "source": [
    "**학습 데이터 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d1fb5ae-f2ab-4350-89c1-b4f320c6cfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76005b93-f5aa-47f6-af04-ea217c86c226",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sql = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")[\"train\"]\n",
    "df_sql = df_sql.to_pandas()\n",
    "df_sql = df_sql.dropna().sample(frac=1, random_state=42)\n",
    "df_sql = df_sql.query(\"db_id != 1\") # 데이터셋에서 평가에 사용하기로 한 db_id가 1인 데이터를 제거\n",
    "\n",
    "for idx, row in df_sql.iterrows():\n",
    "    df_sql.loc[idx, 'text'] = make_prompt(row['context'], row['question'], row['answer'])\n",
    "\n",
    "!mkdir data\n",
    "df_sql.to_csv('data/train.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4a3649-4209-410f-8819-c0d3bf22ba82",
   "metadata": {},
   "source": [
    "**미세 조정 명령어**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb03d757-f374-437f-bf21-ca85bfcea8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = 'beomo/Yi-Ko-6B'\n",
    "finetuned_model = 'yi-ko-6b-text2sql'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb619ff-4a0c-449a-ba23-92084a682bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!autotrain llm \\\n",
    "--train \\\n",
    "--model {base_model} \\\n",
    "--project-name {finetuned-model} \\\n",
    "--data-path data/ \\\n",
    "--text-column test \\\n",
    "--lr 2e-4 \\\n",
    "--batch-size 8 \\\n",
    "--epochs 1 \\\n",
    "--block-size 1024 \\\n",
    "--warmup-ratio 0.1 \\\n",
    "--lora-r 16 \\\n",
    "--lora-alpha 32 \\\n",
    "--lora-dropout 0.05 \\\n",
    "--weight-decay 0.01 \\\n",
    "--gradient-accumulation 8 \\\n",
    "--mixed-precision fp16 \\\n",
    "--use-peft \\\n",
    "--quantization int4 \\\n",
    "--trainer sft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa0d105-1058-4465-b432-2b7f5e60d3de",
   "metadata": {},
   "source": [
    "**LoRA 어댑터 결합 및 허깅페이스 허브 업로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b959e4b1-7a4f-4b08-be7e-c26684ed2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f06f59-71dd-4a79-b0a5-d60e7baa4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = start_model\n",
    "device_map = {\"\": 0}\n",
    "\n",
    "# LoRA와 기초 모델 파라미터 합치기\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    low_cpu_mem_usage=True,\n",
    "    return_dict=True,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=device_map,\n",
    ")\n",
    "\n",
    "model = PeftModel.from_pretrained(base_model, new_model)\n",
    "model = model.merge_and_unload()\n",
    "\n",
    "# 토크나이저 설정\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "# 허깅페이스 허브에 모델 및 토크나이저 저장\n",
    "model.push_to_hub(new_model, use_temp_dir=False)\n",
    "tokenizer.push_to_hub(new_model, use_temp_dir=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446b8e4e-e693-4e70-bcc4-ee33dc57ecd5",
   "metadata": {},
   "source": [
    "**미세 조정한 모델로 예시 데이터에 대한 SQL 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5037cbc3-178e-4bf8-be53-f3d0cafa5879",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"shargrilar/yi-ko-6b-text2sql\"\n",
    "hf_pipe = make_inference_pipeline(model_id)\n",
    "\n",
    "hf_pipe(example, do_sample=False,\n",
    "        return_full_text=False, max_length=1024, truncation=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7def18-c47e-4921-a7aa-5613b4689da1",
   "metadata": {},
   "source": [
    "**미세 조정한 모델 성능 측정**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4eb00ca-1507-4424-9844-baab800ab47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sql 생성 수행\n",
    "gen_sqls = hf_pipe(df['prompt'].tolist(), do_sample=False,\n",
    "                   return_full_text=False, max_length=1024, truncation=True)\n",
    "gen_sqls = [x[0]['generated_text'] for x in gen_sqls]\n",
    "df['gen_sql'] = gen_sqls\n",
    "\n",
    "# 평가를 위한 requests.jsonl 생성\n",
    "eval_filepath = \"text2sql_evaluation_finetuned.jsonl\"\n",
    "make_requests_for_gpt_evaluation(df, eval_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08240c94-186d-43ab-ad77-db7fe6e20048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-4 평가 수행\n",
    "!python3 api_request_parallel_processor.py \\\n",
    "    --requests_filepath requests/{eval_filepath} \\\n",
    "    --save_filepath results/{eval_filepath} \\\n",
    "    --request_url https://api.openai.com/v1/chat/completions \\\n",
    "    --max_requests_per_minute 2500 \\\n",
    "    --max_tokens_per_minute 100000 \\\n",
    "    --token_encoding_name cl100k_base \\\n",
    "    --max_attempts 5 \\\n",
    "    --logging_level 20 "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
