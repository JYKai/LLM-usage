# 검색 증강 생성(RAG)
검색 증강 생성이란, LLM에게 단순히 질문이나 요청만 전달하고 생성하는 것이 아니라 답변에 필요한 충분한 정보와 맥락을 제공하고 답변하도록 하는 방법을 말한다.
- 답변에 필요한 정보를 '검색(retrieval)'을 통해 선택하기 때문에 '검색을 통해 보충한 생성'이라는 의미로 붙은 이름이다.

## 데이터 저장
데이터 소스의 텍스트를 임베딩 모델을 사용해 임베딩 벡터로 변환한다. 변환한 임베딩 벡터는 벡터 사이의 거리를 기준으로 검색하는 특수한 데이터베이스인 벡터 데이터베이스에 저장한다.

벡터 데이터베이스는 임베딩 벡터의 저장소이고 입력한 벡터와 유사한 벡터를 찾는 기능을 제공한다.
- 오픈소스 : Chroma, Milvus
- 사업 : Pinecone, Weaviate
- 관계형 데이터베이스 : PostgreSQL
    - 최근 벡터 검색 기능을 도입하고 강화하고 있다.

특정 문장(검색 쿼리)으로 검색을 수행하는 경우 임베딩 모델을 통해 검색 쿼리도 벡터로 변환해 벡터 데이터베이스에서 위치를 찾고 쿼리 임베딩과 가장 가까운 벡터를 찾는다.
- 일반적으로 유클리드 거리, 코사인 유사도를 활용한다.

## 프롬프트에 검색 결과 통합
LLM은 결과를 생성할 때 프롬프트만 입력으로 받는다.
- 앞서 저장한 텍스트를 LLM에 전달하기 위해서는 사용자의 요청과 관련이 큰 문서를 벡터 데이터베이스에서 찾고 검색 결과를 프롬프트에 통합해야 한다.
- 검색 결과는 프롬프트 모듈에서 사용자의 요청과 하나로 통합된다.

## 라마인덱스로 RAG 구현하기
라마인덱스는 기본 임베딩 모델로 OpenAI의 text-embeddings-ada-002 모델을 사용하고 기본 벡터 데이터베이스로 인메모리(in-memory) 방식의 벡터 데이터베이스를 사용한다.

# LLM 캐시
LLM 캐시는 LLM 추론을 수행할 때 사용자의 요청과 생성 결과를 기록하고 이후에 동일하거나 비슷한 요청이 들어오면 새롭게 텍스트를 생성하지 않고 이전의 생성 결과를 가져와 바로 응답함으로써 LLM 생성 요청을 줄인다.

## LLM 캐시 작동 원리

LLM 캐시의 두 가지 방식  
1. 일치(exact match) 캐시
    - 요청이 완전히 일치하는 경우 저장된 응답을 반환
2. 유사 검색(similar search) 캐시
    - 이전에 '유사'한 요청이 있었는지 확인하기 위해 문자열을 임베딩 모델을 통해 변환한 임베딩 벡터를 비교

# 데이터 검증

## 데이터 검증 방식

1. 규칙 기반
    - 문자열 매칭이나 정규 표현식을 활용해 데이터를 확인하는 방식
2. 분류 또는 회귀 모델
    - 긍부정 분류 모델을 만들어 부정 스코어를 기반으로 로직 설계
3. 임베딩 유사도 기반
    - 특정 민감한 내용과 관련된 텍스트를 임베딩 벡터로 만들어 요청의 임베딩과 비교
4. LLM 활용
    - LLM의 응답 활용

# 데이터 로깅
LLM 애플리케이션의 경우 입력이 동일해도 출력이 달라질 수 있기 때문에 어떤 입력에서 어떤 출력을 반환했는지 반드시 기록해야한다.