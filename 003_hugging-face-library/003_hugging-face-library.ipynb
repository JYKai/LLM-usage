{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4825728-8761-4c9e-a13a-600ff3d3b9e9",
   "metadata": {},
   "source": [
    "# 허깅페이스 트랜스포머란?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1657bd7b-2dcb-4c91-97d5-d86211159b89",
   "metadata": {},
   "source": [
    "**BERT와 GPT-2 모델을 활용할 때 허깅페이스 트랜스포머 코드 비교** \n",
    "- AutoModel, AutoTokenizer 클래스 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf7b1df-477a-43bc-b643-1775c28ab334",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.40.1 datasets==2.19.0 huggingface_hub==0.23.0 -qqq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10eba210-36b2-45ba-aa9f-bb51576df435",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1963202-8f4b-4442-9b5c-840558446b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"What is Huggingface Transformers?\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1bd8ef-7fed-4a76-a110-163d5b40fe3f",
   "metadata": {},
   "source": [
    "### BERT 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "449ec1c7-5321-4f90-b004-e15688397ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "096ed2201926418494a6c69db87fb219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43118b60299144a7b269ee962b5577ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3158eff77e874d31931c918df887dbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f215bb7c629b4660b492db6de8c10842",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d7fa0974d74577852c4a7646ec2bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# BERT 모델 활용\n",
    "bert_model = AutoModel.from_pretrained(\"bert-base-uncased\") # 모델 불러오기\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\") # 토크나이저 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a15959-3e63-4aa6-851f-37596989fe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = bert_tokenizer(text, return_tensors='pt') # 입력 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e9a54706-ac6c-4391-880e-1f7583ec93d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  2054,  2003, 17662, 12172, 19081,  1029,   102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "027a21b9-a8f9-45a2-9f7f-adb6e99962fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_output = bert_model(**encoded_input) # 모델에 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99756a16-6356-4600-9f42-7b143dc3f68a",
   "metadata": {},
   "source": [
    "### GPT-2 모델 활용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dae0229c-d4a2-418b-98ea-7b7e59a714e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b3b6b721634e74a955b202ba215c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437cc1531cb243e2a201ddc712a1e4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3252ed52b154f62999ccba68480d8b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c1df57ae44422eba05c4da9387bb91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeb59ef4a8384c1ab99d0e2aab6f5e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c886e54a1f9d42bca67b42911a73bc01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gpt_model = AutoModel.from_pretrained(\"gpt2\")\n",
    "gpt_tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "encoded_input = gpt_tokenizer(text, return_tensors='pt')\n",
    "gpt_output = gpt_model(**encoded_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd03001-d6fb-4bcf-a911-ed914ff7374d",
   "metadata": {},
   "source": [
    "# 허깅페이스 라이브러리 사용법 익히기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834e2792-acd8-4819-b03d-edbf92a9c839",
   "metadata": {},
   "source": [
    "## 모델 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de6608a4-6b9e-4b66-96cc-49cf50af4b4a",
   "metadata": {},
   "source": [
    "**모델 아이디로 모델 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73ac9de1-c0f6-4464-9752-23d3a165e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167b1ee3-bd43-47f0-a1f7-e8b968b3038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d01b47264f46ea94ff5df50945367b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "488b5f4d74f9416aaf48cfa8016c506b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'klue/roberta-base'\n",
    "model = AutoModel.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe68ece-3c0b-418f-87fc-8ad7a5b3b1cf",
   "metadata": {},
   "source": [
    "**classification head가 포함된 모델 불러오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3db310a-341b-43af-9617-d48e8059d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b3b142e-0d74-41a2-84c6-4b914315a520",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d335c7812eb348daa7e47ba8676bb438",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a46e460e57642f08c72ee80389b3c1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'SamLowe/roberta-base-go_emotions'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55ef236-2b2c-4ed0-aa03-8b65609416e0",
   "metadata": {},
   "source": [
    "**분류 헤드가 랜덤으로 초기화된 모델 불러오기**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "86364e4d-d9bf-4766-b862-a5002c1b4d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e4941a48-0685-43a7-a3cd-80a73bc2567f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = 'klue/roberta-base'\n",
    "classification_model = AutoModelForSequenceClassification.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8bf3ca-38ab-4055-bf89-c92da6bfe992",
   "metadata": {},
   "source": [
    "## 토크나이저 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40bbe2ba-867c-48e8-bd6f-031f0c9b3fe4",
   "metadata": {},
   "source": [
    "**토크나이저 불러오기**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9674844f-5182-43d2-811b-ba2c40ff5473",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac087bf6-a1cc-4946-a350-bc0aeaa3f593",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab0ebb5af7c34295b1daa34594139e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216590121bb54b0d8408c1b2fe957e92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6aeb29c0c7d541c8a71878bef4a8debc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4935f0612b384580b4fa2538b2644dde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = 'klue/roberta-base'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936dd6e2-ecd6-459a-94a3-723206b2388e",
   "metadata": {},
   "source": [
    "**토크나이저 사용하기**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a3d3383-d086-4544-81c2-a0c32ca1f663",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = tokenizer(\"토크나이저는 텍스트를 토큰 단위로 나눈다\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d467acfe-fb76-46a9-ab3d-05ef1573a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [0, 9157, 7461, 2190, 2259, 8509, 2138, 1793, 2855, 5385, 2200, 20950, 2], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "52591c30-7c20-4483-9f86-44d4381c1b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '토크', '##나이', '##저', '##는', '텍스트', '##를', '토', '##큰', '단위', '##로', '나눈다', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.convert_ids_to_tokens(tokenized['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d1bd8e8c-3608-4358-9e13-db3c13dd53ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 05:35:43.844241: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 05:35:43.850266: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 05:35:43.856987: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 05:35:43.858872: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 05:35:43.863819: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 05:35:44.313885: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] 토크나이저는 텍스트를 토큰 단위로 나눈다 [SEP]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized['input_ids']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5328b3cb-e7d7-4ad7-bea8-663c345cb814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "토크나이저는 텍스트를 토큰 단위로 나눈다\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(tokenized['input_ids'], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7945af95-d33d-4750-8b98-6c861eb86012",
   "metadata": {},
   "source": [
    "**토크나이저에 여러 문장 넣기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2368589e-f7e1-4066-bec7-f0afb6c8d718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1656, 1141, 3135, 6265, 2], [0, 864, 1141, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['첫 번째 문장', '두 번째 문장'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fad2c6-e9ab-4e87-be48-3e100e63e05c",
   "metadata": {},
   "source": [
    "**하나의 데이터에 여러 문장이 들어가는 경우**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e328ba70-059f-4843-ab00-a69d331237bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1656, 1141, 3135, 6265, 2, 864, 1141, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([['첫 번째 문장', '두 번째 문장']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7195b137-5b0a-484e-8ede-579c0eb275e3",
   "metadata": {},
   "source": [
    "**토큰 아이디를 문자열로 복원**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3f0c0a52-1e2d-4751-9dcf-6fee64b90f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 첫 번째 문장 [SEP]', '[CLS] 두 번째 문장 [SEP]']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_tokenized_result = tokenizer(['첫 번째 문장', '두 번째 문장'])['input_ids']\n",
    "tokenizer.batch_decode(first_tokenized_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b583a0c7-3f16-4d11-97e0-4a8883323c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] 첫 번째 문장 [SEP] 두 번째 문장 [SEP]']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_tokenized_result = tokenizer([['첫 번째 문장', '두 번째 문장',]])['input_ids']\n",
    "tokenizer.batch_decode(second_tokenized_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1093be6c-a6d3-4efe-921b-ffc08e79fee1",
   "metadata": {},
   "source": [
    "**BERT 토크나이저와 RoBERTa 토크나이저**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47b946f2-f330-4ff4-96fb-a9bc6a82f92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7a1ef50da043ddb5f9b2513354d16a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/289 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1fa509cb504da3b8b2128e1ab149ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/425 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ab729c75ab4bd9b46113a691576b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee855e607c0248b6836fde0dddd2522b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/495k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be6d76396944c85b058ac5b68de2070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 1656, 1141, 3135, 6265, 3, 864, 1141, 3135, 6265, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('klue/bert-base')\n",
    "bert_tokenizer([['첫 번째 문장', '두 번째 문장']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f446224-736b-48dd-b80d-d3e82ba61016",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1656, 1141, 3135, 6265, 2, 864, 1141, 3135, 6265, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roberta_tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "roberta_tokenizer([['첫 번째 문장', '두 번째 문장']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "12ccc70b-3005-4a7b-90e8-1ceec84422a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54db993104e74a1691f0a4f102d94e21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28efa585728e45c8b0c36c2951a2c489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0504398fd1c4dcc8088619456685488",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2a3c23eba84b32aa09c3078f61b00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc8ba8a53da4da0b66af3e3d7233e24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 9502, 3645, 2, 2, 10815, 3645, 2]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_roberta_tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
    "en_roberta_tokenizer([['first sentence', 'second sentence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9fadb6-0fa4-4fca-91d9-b84ed7b82c02",
   "metadata": {},
   "source": [
    "**attention_mask 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5bb5ed39-4c2e-4f08-8304-cd580a32df2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[0, 1656, 1141, 3135, 6265, 2073, 1599, 2062, 2, 1, 1, 1, 1, 1, 1, 1], [0, 864, 1141, 3135, 6265, 2073, 1656, 1141, 3135, 6265, 2178, 2062, 831, 647, 2062, 2]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(['첫 번째 문장은 짧다', '두 번째 문장은 첫 번째 문장보다 더 길다'], padding='longest')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7da863c8-9bbb-45dd-b7cf-062ba8ed26ef",
   "metadata": {},
   "source": [
    "## 데이터셋 활용하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc9cffb-6cfd-4209-86b5-1861282313c2",
   "metadata": {},
   "source": [
    "**KLUE MRC 데이터셋 다운로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de47df41-b053-4281-81a7-91b53de40a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fd69113-5c5f-4333-aeba-b5062fdbdf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fcfc514619b4ee5a6a20e3b1cec3ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/22.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edbcff6545944249895081af06748505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/21.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88dbc16c7d5b4243a99dd14c8a78d656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/8.68M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de4db32308de437494eb53711bd60cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/17554 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7cd74fe9c44176905b03d69c794fa8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/5841 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "klue_mrc_dataset = load_dataset('klue', 'mrc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4b71228-c570-49d9-b71a-66123104d53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
       "        num_rows: 17554\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['title', 'context', 'news_category', 'source', 'guid', 'is_impossible', 'question_type', 'question', 'answers'],\n",
       "        num_rows: 5841\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_mrc_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1f2e52-9a91-412d-b24a-471509eaf579",
   "metadata": {},
   "source": [
    "**로컬의 데이터 활용하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cbcb2c87-289d-497d-9923-19dc6cc8e08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1745b9ad-421e-4ed6-a0f2-5d96a6626ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 로컬 CSV 데이터 파일을 활용\n",
    "# dataset = load_dataset('csv', data_files='my_file.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c89415cd-9425-4ff6-b4be-ac719fb843dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파이썬 딕셔너리 활용\n",
    "from datasets import Dataset\n",
    "\n",
    "my_dict = {\"a\": [1, 2, 3]}\n",
    "dataset = Dataset.from_dict(my_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b5b4515c-47de-469c-b28d-5b5f117cf386",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 판다스 데이터프레임 활용\n",
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "df = pd.DataFrame({\"a\": [1, 2, 3]})\n",
    "dataset = Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6caaf-6d42-46ce-8916-08828dd74cab",
   "metadata": {},
   "source": [
    "# 모델 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b25ff5-e1d0-44d9-8a4e-b8925956ce61",
   "metadata": {},
   "source": [
    "한국어 기사 제목을 바탕으로 기사의 카테고리를 분류하는 텍스트 분류 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be4ad12-5bbc-4d1f-be13-c3de17689281",
   "metadata": {},
   "source": [
    "## 데이터 준비"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7515509-9e1a-4f58-b189-147859810b50",
   "metadata": {},
   "source": [
    "데이터셋\n",
    "- KLUE 데이터셋의 YNAT 서브셋 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f398b41a-6d51-44ae-81c9-75b8d7ee41ad",
   "metadata": {},
   "source": [
    "**모델 학습에 사용할 연합 뉴스 데이터셋 다운로드**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c799a69-977e-4aac-9869-4cb1b7a91550",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4f9128b-196a-4a58-a9e9-f54a58831e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "klue_tc_train = load_dataset('klue', 'ynat', split='train')\n",
    "klue_tc_eval = load_dataset('klue', 'ynat', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e783a40-e553-45c5-9796-1fb7b06af8b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['guid', 'title', 'label', 'url', 'date'],\n",
       "    num_rows: 45678\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2563d4fd-7b2f-4274-929f-08c22de16896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'ynat-v1_train_00000',\n",
       " 'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영',\n",
       " 'label': 3,\n",
       " 'url': 'https://news.naver.com/main/read.nhn?mode=LS2D&mid=shm&sid1=105&sid2=227&oid=001&aid=0008508947',\n",
       " 'date': '2016.06.30. 오전 10:36'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29eb17da-0ead-43dc-b95a-61fd97b07ddb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label'].names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c407f-b32e-452c-b9ab-b26914cdd019",
   "metadata": {},
   "source": [
    "**실습에 사용하지 않는 불필요한 컬럼 제거**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffbbf5da-1a03-4df3-a9a3-ea8f9aafe8b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "klue_tc_train = klue_tc_train.remove_columns(['guid', 'url', 'date'])\n",
    "klue_tc_eval = klue_tc_eval.remove_columns(['guid', 'url', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c71b45c3-14aa-4855-adb4-a60f29514081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'label'],\n",
       "    num_rows: 45678\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7322406d-ed90-4548-a0f3-fc2d6557bb31",
   "metadata": {},
   "source": [
    "**카테고리를 문자로 표기한 label_str 컬럼 추가**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53b27f85-dcb9-42ac-bc29-ed5f97e9788c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ClassLabel(names=['IT과학', '경제', '사회', '생활문화', '세계', '스포츠', '정치'], id=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6717f0be-0ccc-47c8-b7a9-7750d5be1528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'경제'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train.features['label'].int2str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f63cec-4750-4391-bebd-0592db0fba0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "klue_tc_label = klue_tc_train.features['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0aad8df-24bf-429f-9dc5-a6d6bab2cddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_str_label(batch):\n",
    "    batch['label_str'] = klue_tc_label.int2str(batch['label'])\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b82fde9-3a3a-4290-9f44-68322141826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "klue_tc_train = klue_tc_train.map(make_str_label, batched=True, batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a48b2bd-f719-4d85-8c88-613d8744ccf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '유튜브 내달 2일까지 크리에이터 지원 공간 운영', 'label': 3, 'label_str': '생활문화'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_tc_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00218d62-0cee-4edc-9b8e-87a6b4909f82",
   "metadata": {},
   "source": [
    "**학습/검증/테스트 데이터셋 분할**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4bc4e271-a7ae-4c07-b11a-d3f3d1687225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = klue_tc_train.train_test_split(test_size=10000, shuffle=True, seed=42)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0bd923f7-941b-4e01-a608-2f1078212ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = klue_tc_eval.train_test_split(test_size=1000, shuffle=True, seed=42)\n",
    "test_dataset = dataset['test']\n",
    "valid_dataset = dataset['train'].train_test_split(test_size=1000, shuffle=True, seed=42)['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef1feab-1030-4b1a-b56b-d55859f84187",
   "metadata": {},
   "source": [
    "## 트레이너 API를 사용해 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2425edf0-abbf-4cfe-8633-8303b567bd25",
   "metadata": {},
   "source": [
    "**Trainer를 사용한 학습: (1) 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b7d5ff2-9cfb-421a-8f09-ec0bf4c8c58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-16 07:40:24.855000: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-16 07:40:24.861956: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-16 07:40:24.869925: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-16 07:40:24.872319: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-16 07:40:24.878527: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-10-16 07:40:25.240779: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    AutoModelForSequenceClassification,\n",
    "    AutoTokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "46b263c3-e447-477f-a304-e37130ae49d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"title\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db225bd8-cdea-4c6d-a0cb-c44a49bc2c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"klue/roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_dataset.features['label'].names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f95c6d2-3c77-4472-9132-784912973307",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d39a8666-683f-4365-b067-8186b5f34323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd57ff393c841c4a47993334fa1be50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "valid_dataset = valid_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0c622eb9-ff13-4f88-a0f3-9a6aeb1357fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'label', 'label_str', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 10000\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff396ce-cef2-45b7-9741-a3f09c1d9ccf",
   "metadata": {},
   "source": [
    "**Trainer를 사용한 학습: (2) 학습 인자와 평가 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c96f523-39a8-4051-904a-621b3d565007",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    push_to_hub=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b573109-2a4a-4db0-8416-98965cd007c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": (predictions == labels).mean()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce87203-2966-452b-83f2-3bbbf562dff7",
   "metadata": {},
   "source": [
    "**Trainer를 사용한 학습: (3) 학습 진행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "037931db-961f-4dc3-8bc8-0d086e797e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=valid_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "454becb2-451c-4009-b536-3969ab05efae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3750' max='3750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3750/3750 06:36, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.621700</td>\n",
       "      <td>0.959795</td>\n",
       "      <td>0.747000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.402600</td>\n",
       "      <td>0.632843</td>\n",
       "      <td>0.842000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.695569</td>\n",
       "      <td>0.848000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3750, training_loss=0.4305603108723958, metrics={'train_runtime': 397.1058, 'train_samples_per_second': 75.547, 'train_steps_per_second': 9.443, 'total_flos': 7893686016000000.0, 'train_loss': 0.4305603108723958, 'epoch': 3.0})"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "62224fff-651c-4dc8-99fe-acad423482ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [125/125 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.5794709324836731,\n",
       " 'eval_accuracy': 0.869,\n",
       " 'eval_runtime': 4.1023,\n",
       " 'eval_samples_per_second': 243.766,\n",
       " 'eval_steps_per_second': 30.471,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4131f393-d39c-4fce-a40b-e02968544a30",
   "metadata": {},
   "source": [
    "## 트레이너 API를 사용하지 않고 학습하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8419886d-d4c1-4fc9-a4b0-f15a0b7fa3d4",
   "metadata": {},
   "source": [
    "**Traine를 사용하지 않는 학습: (1) 학습을 위한 모델과 토크나이저 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58bdcdad-ff8e-418b-b4ad-ca402a133c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4e0ff99-63a2-4483-af17-643af2f88bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toeknize_function(examples):\n",
    "    return tokenizer(examples[\"title\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "534ec25e-42dd-4556-9de0-56a1834792c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(32000, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_id = \"klue/roberta-base\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(train_dataset.features['label'].names))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f7785-4c97-415d-8cc4-0fefe4d1a3a7",
   "metadata": {},
   "source": [
    "**Trainer를 사용하지 않는 학습: (2) 학습을 위한 데이터 준비**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1b33f03e-332b-448a-9e2d-13bb71b6a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataloader(dataset, batch_size, shuffle=True):\n",
    "    dataset = dataset.map(tokenize_function, batched=True).with_format(\"torch\")\n",
    "    # 데이터셋에 토큰화 수행\n",
    "    dataset = dataest.rename_column(\"label\", \"labels\") # 컬럼 이름 변경\n",
    "    dataset = dataset.remove_columns(colum_names=['title'])\n",
    "    return DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "125fe710-880f-451c-8327-aa1b63d2cae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터로더 만들기\n",
    "train_dataloader = make_dataloader(train_dataset, batch_size=8, shuffle=True)\n",
    "valid_dataloader = make_dataloader(valid_dataset, batch_size=8, shuffle=False)\n",
    "test_dataloader = make_dataloader(test_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef593aa-64ce-4e94-8902-dc761d41fb4f",
   "metadata": {},
   "source": [
    "**Trainer를 사용하지 않는 학습: (3) 학습을 위한 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b3ba370-6767-46d0-b626-c9e39edf0d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in tqdm(data_loader):\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device) # 모델에 입력할 토큰 아이디\n",
    "        attention_mask = batch['attention_mask'].to(device) # 모델에 입력할 어텐션 마스크\n",
    "        labels = batch['labels'].to(device) # 모델에 입력할 레이블\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0014d9-3e77-4824-9680-218a8e1d00b2",
   "metadata": {},
   "source": [
    "**Trainer를 사용하지 않는 학습: (4) 평가를 위한 함수 정의**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "dc58415f-0383-4c2d-9853-91a13c46a0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            logits = outputs.logits\n",
    "            loss = outputs.loss\n",
    "            total_loss += loss.item()\n",
    "            preds = torch.argmax(logits, dim=-1)\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "    avg_loss = total_loss / len(data_loader)\n",
    "    accuracy = np.mean(np.array(predictions) == np.array(true_labels))\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f78603-1ebe-4c83-8a0d-a6703b067b71",
   "metadata": {},
   "source": [
    "**Trainer를 사용하지 않는 학습: (5) 학습 수행**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "264a616b-cba3-4275-9cb2-aca9d5bdd9d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:521: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4e2a66cf2d49b3ae2958e975fd6d41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6306635253489018\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb00ee515c04269a169c8b7198ae46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.5637158288359642\n",
      "Validation accuracy: 0.818\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1} / {num_epochs}\")\n",
    "    train_loss = train_epoch(model, train_dataloader, optimizer)\n",
    "    print(f\"Training loss: {train_loss}\")\n",
    "    valid_loss, valid_accuracy = evaluate(model, valid_dataloader)\n",
    "    print(f\"Validation loss: {valid_loss}\")\n",
    "    print(f\"Validation accuracy: {valid_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a68e36-8251-4c5e-97f2-58b40a664420",
   "metadata": {},
   "source": [
    "## 학습한 모델 업로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd3340-57fb-4dce-ba7a-d9698f9ae3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\"본인의 허깅페이스 토크 입력\")\n",
    "repo_id = f\"본인의 아이디 입력/roberta-base-klue-ynat-classification\"\n",
    "\n",
    "# Trainer를 사용한 경우\n",
    "trainer.push_to_hub(repo_id)\n",
    "\n",
    "# 직접 학습한 경우\n",
    "model.push_to_hub(repo_id)\n",
    "tokenizer.push_to_hub(repo_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0273ed6-be9f-472e-a2b1-a106d3df310a",
   "metadata": {},
   "source": [
    "# 모델 추론하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d972eb52-e402-433b-a8e3-ecf87cd15db7",
   "metadata": {},
   "source": [
    "## 파이프라인을 활용한 추론"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a14736-b15d-480e-a433-de36dc379696",
   "metadata": {},
   "source": [
    "**학습한 모델을 불러와 pipeline을 활용해 추론하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ea1dea94-80f1-4dbe-8616-4e8c737e84de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ac951c-589c-4c51-acfa-cab5892f43d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"본인의 아이디 입력/roberta-base-klue-ynat-classification\"\n",
    "\n",
    "model_pipeline = pipeline(\"text-classification\", model=model_id)\n",
    "\n",
    "model_pipeline(dataset[\"title\"][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb9310-5d9f-44bf-9326-945e0c06c535",
   "metadata": {},
   "source": [
    "## 직접 추론하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78e5a42-96d8-46c0-9a01-dd1322c09ded",
   "metadata": {},
   "source": [
    "**커스텀 파이프라인 구현**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2cd4a62e-2837-4f48-8b34-2f8eaae27a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import softmax\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "920c22fc-b9c1-49e2-9ce2-55fa34166029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomPipeline:\n",
    "    def __init__(self, model_id):\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_id)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "        self.model.eval()\n",
    "\n",
    "    def __call__(self, texts):\n",
    "        tokenized = self.tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(**tokenized)\n",
    "            logits = outputs.logits\n",
    "\n",
    "        probabilities = softmax(logits, dim=-1)\n",
    "        scores, labels = torch.max(probabilities, dim=-1)\n",
    "        labels_str = [self.model.config.id2label[label_idx] for label_idx in labels.tolist()]\n",
    "\n",
    "        return [{\"label\": label, \"score\": score.item()} for label, score in zip(labels_str, scores)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b2ea62-f9c7-4850-9c81-b2fba1bbe6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pipeline = CustomPipeline(model_id)\n",
    "custom_pipeline(dataset[\"title\"][:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
