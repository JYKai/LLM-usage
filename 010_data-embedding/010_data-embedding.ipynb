{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9ec4a21-a041-4f8d-b641-1971f86adf54",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install sentence-transformers==2.7.0 faiss-cpu==1.8.0 llama-index-embeddings-huggingface==0.2.0 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3108dc8e-a115-4702-9e52-2637e87dfbf3",
   "metadata": {},
   "source": [
    "# Understanding Text Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bac9c5-359f-4749-bc02-bae1bd7f0ba2",
   "metadata": {},
   "source": [
    "## Advantages of sentence embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184edfb3-af71-4dcd-adc6-ece6fa1ce2fc",
   "metadata": {},
   "source": [
    "**Computing word-to-word similarity using sentence embedding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a22aa6-84ce-45ee-a683-2c7a54770bc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7352313ef5c48e8a8470e5b1a629c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d930cc6739bb419e945ba6131e83baaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa382ca2e7324273af935c1f3cf44c6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ad32ebd2964265b1a3b09ffca59ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c80cf14f78f475594fe749949541d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb6840d0a2324e878ce4ee314f5916b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e04b6a15f24967a3bc9c06a372076e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702992bdf4634a7ea3ccb4051fc33a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/336k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700ff3565f0543b3be9b5dee21f8d703",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/967k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "949699df5f604addb5d58eabcbec442a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c7c503c5d449dbadd2081399d03327",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999999 , 0.46143383, 0.5178716 ],\n",
       "       [0.46143383, 1.        , 0.44198984],\n",
       "       [0.5178716 , 0.44198984, 0.99999994]], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "smodel = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "dense_embeddings = smodel.encode(['School', 'Study', 'Exercise'])\n",
    "\n",
    "cosine_similarity(dense_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c819bc74-092e-437c-8fec-db108558ef3d",
   "metadata": {},
   "source": [
    "## One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda35cc1-f2a4-4bc4-8e44-d8bb9a7d1cd2",
   "metadata": {},
   "source": [
    "**Limitations of one-hot encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0910f271-b846-4ee2-8950-ae3e3e54dcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "word_dict = {\n",
    "    \"school\": np.array([[1, 0, 0]]),\n",
    "    \"study\": np.array([[0, 1, 0]]),\n",
    "    \"workout\": np.array([[0, 0, 1]])\n",
    "}\n",
    "\n",
    "cosine_school_study = cosine_similarity(word_dict['school'], word_dict['study']) # array([[0.]])\n",
    "cosine_school_workout = cosine_similarity(word_dict['school'], word_dict['workout']) # array([[0.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "478168f6-cd6b-49dc-99d8-84537c668317",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0.]]), array([[0.]]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_school_study, cosine_school_workout"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f90cc91-64a4-4c8c-a4a4-c96ad3986022",
   "metadata": {},
   "source": [
    "# Method of Sentence Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8a33811-87f3-4805-88a0-68aa1c18759e",
   "metadata": {},
   "source": [
    "## Two ways to compute relationships between sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7db1a24-65e5-48d9-a089-390a1638c407",
   "metadata": {},
   "source": [
    "### Bi-encoder structure\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baae5994-9347-4200-b3b0-768f416863bb",
   "metadata": {},
   "source": [
    "**Bi-encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e9571e28-af0f-43c7-9bd1-bac0d266f89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1103e75972e247898e574754d94a2565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/546 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796440637a3540aab2b441477821cea3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/443M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce4c08fefe14d43bcc7072302399652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/375 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4728b1c013c437797dc868cec91598e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f67f553a724e60beba5f05391c8074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6f374c9542401c8356e71210e596ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/173 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "# BERT model\n",
    "word_embedding_model = models.Transformer('klue/roberta-base')\n",
    "\n",
    "# Input pooling layer demension\n",
    "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
    "\n",
    "# Combine two modules\n",
    "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ddf913b-2424-4b29-8de1-6e6dacb3339b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: RobertaModel \n",
       "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37350874-38b1-4607-947d-4061c443e15b",
   "metadata": {},
   "source": [
    "**average mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d70943-6608-4f15-b1a2-bef4bd914f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] # last layer output\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "    sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    return sum_embeddings / sum_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed790fdf-3ed4-40f8-b16a-1c00287a1b28",
   "metadata": {},
   "source": [
    "**max mode**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6f0f516-ee5f-48a5-82f6-d5fd88877f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_poolint(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    token_embeddings[input_mask_expanded == 0] = -1e9\n",
    "    return torch.max(token_embeddings, 1)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bde9933-6d6b-45b4-b803-52c3694609e9",
   "metadata": {},
   "source": [
    "## Create text and image embeddings with Sentence-Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5360b204-57be-4ad3-9e66-c6da60c5a734",
   "metadata": {},
   "source": [
    "**Korean sentence embedding model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4042504-37b4-43e7-bd44-13495b9f909b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.6410, 0.1887],\n",
       "        [0.6410, 1.0000, 0.2730],\n",
       "        [0.1887, 0.2730, 1.0000]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "\n",
    "embs = model.encode(['잠이 안 옵니다',\n",
    "                     '졸음이 옵니다',\n",
    "                     '기차가 옵니다'])\n",
    "\n",
    "cos_scores = util.cos_sim(embs, embs)\n",
    "cos_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a128c004-ae3d-45f5-a8d5-c3a8ef3ad5cb",
   "metadata": {},
   "source": [
    "**Computation of image and text embeddings using CLIP**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f9210d5-04c1-4076-8d39-7de85775ce68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad7ab18b94e41c48940f60f4195aed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/122 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba1e77ce6c64d6f8450a509678bf2f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c0b3b509ac41d295b8ed0fb20af9a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.91k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd15c4b495e545d8b294f0594f7bf098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/merges.txt:   0%|          | 0.00/525k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f86d20f961694a318738969375bac267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/vocab.json:   0%|          | 0.00/961k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97025bc12d841f7ae21fd396e5597f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3229de9bfe624337bcba2cfcf7e43706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3b6f2792cd4dfbb242dd6a72d53bb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/config.json:   0%|          | 0.00/4.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dace7f621fe94ba5b3f093c53a382759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/tokenizer_config.json:   0%|          | 0.00/604 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "116ae9f512d344fd8790635b654d1170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0_CLIPModel/pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 04:13:51.648543: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-22 04:13:51.745097: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-22 04:13:51.748895: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-22 04:13:51.748906: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-11-22 04:13:51.768134: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-22 04:13:52.118036: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-22 04:13:52.118085: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-22 04:13:52.118091: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.2722, 0.1796],\n",
       "        [0.2220, 0.3563]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "img_embs = model.encode([Image.open('dog.jpg'), Image.open('cat.jpg')])\n",
    "text_embs = model.encode(['A dog on grass', 'Brown cat on yellow background'])\n",
    "\n",
    "cos_scores = util.cos_sim(img_embs, text_embs)\n",
    "cos_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d5b98b-69dd-4419-926e-49a2d982010d",
   "metadata": {},
   "source": [
    "# Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49201fa3-89e3-416a-8036-4e3637d4eeca",
   "metadata": {},
   "source": [
    "## Implementation semantic search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "810f07ae-43ea-42a9-98c9-7455dd5b1709",
   "metadata": {},
   "source": [
    "**Load dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e5db2506-8f3e-4e5b-9ed9-3d69ed6571c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "klue_mrc_dataset = load_dataset('klue', 'mrc', split='train')\n",
    "sentence_model = SentenceTransformer('snunlp/KR-SBERT-V40K-klueNLI-augSTS')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a4ed85-a26f-4195-9f66-aea0999ddf3d",
   "metadata": {},
   "source": [
    "**Transformation data to sentence embeddings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "208b1a84-b3d1-4a05-a15c-954d4d05dadc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 768)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_mrc_dataset = klue_mrc_dataset.train_test_split(train_size=1000, shuffle=False)['train']\n",
    "\n",
    "embeddings = sentence_model.encode(klue_mrc_dataset['context'])\n",
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c871756d-cc66-479d-962f-61a38ba1ff4c",
   "metadata": {},
   "source": [
    "**KNN search index**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e62f60fc-7aaf-491f-b1b4-1f547180d9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "\n",
    "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "index.add(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d6bf34-f05c-4c84-b542-cd8f8fb90931",
   "metadata": {},
   "source": [
    "**Procs of semantic search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e7167b-e2af-4ed5-a429-7fb8d1d4828e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 \n",
      "연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그\n",
      "연구 결과에 따르면, 오리너구리의 눈은 대부분의 포유류보다는 어류인 칠성장어나 먹장어, 그\n"
     ]
    }
   ],
   "source": [
    "query = \"이번 연도에는 언제 비가 많이 올까?\"\n",
    "query_embedding = sentence_model.encode([query])\n",
    "distances, indices = index.search(query_embedding, 3)\n",
    "\n",
    "for idx in indices[0]:\n",
    "    print(klue_mrc_dataset['context'][idx][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92008777-836e-426e-a002-70333b911014",
   "metadata": {},
   "source": [
    "**Limitation of semantic search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "625085e8-e222-41c9-a31b-c2194290b42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
      "1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음\n",
      "1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음\n"
     ]
    }
   ],
   "source": [
    "query = klue_mrc_dataset[3]['context']\n",
    "query_embedding = sentence_model.encode([query])\n",
    "distances, indices = index.search(query_embedding, 3)\n",
    "\n",
    "for idx in indices[0]:\n",
    "    print(klue_mrc_dataset['context'][idx][:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e6ac44-7c13-4e6c-988b-0ca723bcefcf",
   "metadata": {},
   "source": [
    "## Use Sentence-Transformers in LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e58b949d-622e-4c35-9566-d2737fe817ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffafda718f443dab83e362c5e9e8929",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9e3178985845b5b3853ee3de33c99e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9f8ba665dd74c5891d6b8b91c382fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.02k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1673ee21a0e840c2860400328f1bb822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8629fe5da4848988629f27a1ec4bff4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/707 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7507675f56e3427ca38439cc37ca0724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d9cef1b8b94043b7dbe24fe97a408f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431f1158b0bb46a78dd13ee67b46f83c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/336k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b3f5e30e2c48afbb1f2a38c75e4648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/967k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4684642c564da9a1fbd8e1747e3e60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2c6dfed16a246f6af68f044bc1ff762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_24688/3569091835.py:6: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM is explicitly disabled. Using MockLLM.\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core import Document\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name='snunlp/KR-SBERT-V40K-klueNLI-augSTS')\n",
    "service_context = ServiceContext.from_defaults(embed_model=embed_model, llm=None)\n",
    "\n",
    "# Use local model\n",
    "# service_context = ServiceContext.from_defaults(embed_model=\"local\")\n",
    "\n",
    "text_list = klue_mrc_dataset[:100]['context']\n",
    "documents = [Document(text=t) for t in text_list]\n",
    "\n",
    "index_llama = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    "    service_context=service_context\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a622424-8e62-4edb-a846-d07bd4da4e27",
   "metadata": {},
   "source": [
    "# Implementation Hybrid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41fd7347-9571-41ea-88c9-3dcd204d6d2c",
   "metadata": {},
   "source": [
    "## BM25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bec5b3c4-c39b-420a-a780-15192e3a83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "from typing import List\n",
    "from collections import defaultdict\n",
    "from transformers import AutoTokenizer, PreTrainedTokenizer\n",
    "\n",
    "class BM25:\n",
    "    def __init__(self, corpus: List[List[str]], tokenizer: PreTrainedTokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.corpus = corpus\n",
    "        self.tokenized_corpus = self.tokenizer(corpus, add_special_tokens=False)['input_ids']\n",
    "        self.n_docs = len(self.tokenized_corpus)\n",
    "        self.avg_doc_lens = sum(len(lst) for lst in self.tokenized_corpus) / len(self.tokenized_corpus)\n",
    "        self.idf = self._calculate_idf()\n",
    "        self.term_freqs = self._calculate_term_freqs()\n",
    "\n",
    "    def _calculate_idf(self):\n",
    "        idf = defaultdict(float)\n",
    "        for doc in self.tokenized_corpus:\n",
    "            for token_id in set(doc):\n",
    "                idf[token_id] += 1\n",
    "        for token_id, doc_frequency in idf.items():\n",
    "            idf[token_id] = math.log(((self.n_docs - doc_frequency + 0.5) / (doc_frequency + 0.5)) + 1)\n",
    "        return idf\n",
    "\n",
    "    def _calculate_term_freqs(self):\n",
    "        term_freqs = [defaultdict(int) for _ in range(self.n_docs)]\n",
    "        for i, doc in enumerate(self.tokenized_corpus):\n",
    "            for token_id in doc:\n",
    "                term_freqs[i][token_id] += 1\n",
    "        return term_freqs\n",
    "\n",
    "    def get_scores(self, query: str, k1: float=1.2, b: float=0.75):\n",
    "        query = self.tokenizer([query], add_special_tokens=False)['input_ids'][0]\n",
    "        scores = np.zeros(self.n_docs)\n",
    "        for q in query:\n",
    "            idf = self.idf[q]\n",
    "            for i, term_freq in enumerate(self.term_freqs):\n",
    "                q_frequency = term_freq[q]\n",
    "                doc_len = len(self.tokenized_corpus[i])\n",
    "                score_q = idf * (q_frequency * (k1 + 1)) / ((q_frequency) + k1 * (1 - b + b * (doc_len / self.avg_doc_lens)))\n",
    "                scores[i] += score_q\n",
    "        return scores\n",
    "\n",
    "    def get_top_k(self, query: str, k: int):\n",
    "        scores = self.get_scores(query)\n",
    "        top_k_indices = np.argsort(scores)[-k:][::-1]\n",
    "        top_k_scores = scores[top_k_indices]\n",
    "        return top_k_scores, top_k_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "87677938-bba7-49fd-badb-398c3886be12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44713859, 0.        , 0.52354835])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check score\n",
    "tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
    "\n",
    "bm25 = BM25(['안녕하세요', '반갑습니다', '안녕 서울'], tokenizer)\n",
    "bm25.get_scores('안녕')\n",
    "\n",
    "# array([0.44713859, 0.        , 0.52354835])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "da6ab4b3-8b43-4f2d-a82a-e3e9708c7c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다\n",
      "인구 비율당 노벨상을 세계에서 가장 많이 받은 나라, 과학 논문을 가장 많이 쓰고 의료 특\n",
      "올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 \n"
     ]
    }
   ],
   "source": [
    "# limitation of BM25\n",
    "\n",
    "bm25 = BM25(klue_mrc_dataset['context'], tokenizer)\n",
    "\n",
    "query = '이번 연도에는 언제 비가 많이 올까?'\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "    print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "# 출력 결과\n",
    "# 갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다\n",
    "# 인구 비율당 노벨상을 세계에서 가장 많이 받은 나라, 과학 논문을 가장 많이 쓰고 의료 특\n",
    "# 올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cb14c4d0-8b53-4884-864f-3ee01acbfae4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
      ";메카동(メカドン)\n",
      ":성우 : 나라하시 미키(ならはしみき)\n",
      "길가에 버려져 있던 낡은 느티나\n",
      ";메카동(メカドン)\n",
      ":성우 : 나라하시 미키(ならはしみき)\n",
      "길가에 버려져 있던 낡은 느티나\n"
     ]
    }
   ],
   "source": [
    "# Procs of BM25 search result\n",
    "\n",
    "query = klue_mrc_dataset[3]['question']\n",
    "_, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "for idx in bm25_search_ranking[:3]:\n",
    "    print(klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "# 출력 결과\n",
    "# 미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
    "# ;메카동(メカドン)\n",
    "# :성우 : 나라하시 미키(ならはしみき)\n",
    "# 길가에 버려져 있던 낡은 느티나\n",
    "# ;메카동(メカドン)\n",
    "# :성우 : 나라하시 미키(ならはしみき)\n",
    "# 길가에 버려져 있던 낡은 느티나"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42cd5455-c687-4433-9797-1525313e71fa",
   "metadata": {},
   "source": [
    "## RRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "50547e28-b3e6-45f2-ab8c-2d5d29f74ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "def reciprocal_rank_fusion(rankings: List[List[int]], k=5):\n",
    "    rrf = defaultdict(float)\n",
    "    for ranking in rankings:\n",
    "        for i, doc_id in enumerate(ranking, 1):\n",
    "            rrf[doc_id] += 1.0 / (k + i)\n",
    "    return sorted(rrf.items(), key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ca87249-9374-4369-8c4b-3c5a639a60aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0.30952380952380953),\n",
       " (3, 0.25),\n",
       " (4, 0.24285714285714285),\n",
       " (6, 0.2111111111111111),\n",
       " (2, 0.16666666666666666),\n",
       " (5, 0.1111111111111111)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "rankings = [[1, 4, 3, 5, 6], [2, 1, 3, 6, 4]]\n",
    "reciprocal_rank_fusion(rankings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e02bae-b2d2-453e-a1cd-360589dec4f9",
   "metadata": {},
   "source": [
    "## Hybrid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "990a0330-8302-46bc-a40f-c9c578250c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_vector_search(query: str, k: int):\n",
    "    query_embedding = sentence_model.encode([query])\n",
    "    distances, indices = index.search(query_embedding, k)\n",
    "    return distances[0], indices[0]\n",
    "\n",
    "def hybrid_search(query, k=20):\n",
    "    _, dense_search_ranking = dense_vector_search(query, 100)\n",
    "    _, bm25_search_ranking = bm25.get_top_k(query, 100)\n",
    "\n",
    "    results = reciprocal_rank_fusion([dense_search_ranking, bm25_search_ranking], k=k)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "41545215-6166-4f9e-92cc-e1b6f341ffa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query sentence:  이번 년도에는 언제 비가 많이 올까?\n",
      "index 0 :  올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 \n",
      "index 232 :  갤럭시S5 언제 발매한다는 건지언제는 “27일 판매한다”고 했다가 “이르면 26일 판매한다\n",
      "index 260 :  “‘마일드세븐’이나 ‘아사히’ 없어도 자영업자나 소비자한테 전혀 지장 없습니다. 담배, 맥\n",
      "================================================================================\n",
      "Search query sentence:  로버트 헨리 딕이 1946년에 매사추세츠 연구소에서 개발한 것은 무엇인가?\n",
      "index 3 :  미국 세인트루이스에서 태어났고, 프린스턴 대학교에서 학사 학위를 마치고 1939년에 로체스\n",
      "index 326 :  1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음\n",
      "index 327 :  1950년대 말 매사추세츠 공과대학교의 동아리 테크모델철도클럽에서 ‘해커’라는 용어가 처음\n"
     ]
    }
   ],
   "source": [
    "query = \"이번 년도에는 언제 비가 많이 올까?\"\n",
    "print(\"Search query sentence: \", query)\n",
    "\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "    print(f'index {idx} : ', klue_mrc_dataset['context'][idx][:50])\n",
    "\n",
    "print('=' * 80)\n",
    "\n",
    "query = klue_mrc_dataset[3]['question']\n",
    "print(\"Search query sentence: \", query)\n",
    "\n",
    "results = hybrid_search(query)\n",
    "for idx, score in results[:3]:\n",
    "    print(f'index {idx} : ', klue_mrc_dataset['context'][idx][:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
