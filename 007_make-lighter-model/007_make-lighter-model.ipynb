{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c86d19c-9224-4a8c-b7c2-f88a2e52c08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers==4.40.1 accelerate==0.30.0 bitsandbytes==0.43.1 auto-gptq==0.7.1 autoawq==0.2.5 optimum==1.19.1 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1e8b91-6304-487a-9f88-654b274425f2",
   "metadata": {},
   "source": [
    "# Reducing model size with quantization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902b0d9f-80f0-4537-8d3b-c0b0b524b48c",
   "metadata": {},
   "source": [
    "## BitsandBytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f528c773-e874-4905-942b-5e603d471811",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`low_cpu_mem_usage` was None, now set to True since model is quantized.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "# 8-bit quantization model\n",
    "bnb_config_8bit = BitsAndBytesConfig(load_in_8bit=True)\n",
    "model_8bit = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\", quantization_config=bnb_config_8bit)\n",
    "\n",
    "# 4-bit quantization model\n",
    "bnb_config_4bit = BitsAndBytesConfig(load_in_4bit=True, bnb_4bit_quant_type='nf4')\n",
    "model_4bit = AutoModelForCausalLM.from_pretrained(\"facebook/opt-350m\", quantization_config=bnb_config_4bit, low_cpu_mem_usage=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1971cc20-d85b-4ff5-b339-f00770038916",
   "metadata": {},
   "source": [
    "## GPTQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dda98af-6900-4b94-95ac-7dc548e8fcee",
   "metadata": {},
   "source": [
    "**GPTQ quantization code**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be435d38-ef0a-4df8-becf-51ac1fe1bb08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-18 05:06:29.287394: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-18 05:06:29.377696: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-18 05:06:29.381533: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-18 05:06:29.381543: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-11-18 05:06:29.400755: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-18 05:06:29.757224: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-18 05:06:29.757271: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-18 05:06:29.757277: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:411: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, input, qweight, scales, qzeros, g_idx, bits, maxq):\n",
      "/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:419: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/usr/local/lib/python3.10/dist-packages/auto_gptq/nn_modules/triton_utils/kernels.py:461: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  @custom_fwd(cast_inputs=torch.float16)\n",
      "CUDA extension not installed.\n",
      "CUDA extension not installed.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13e66d5b87fd4bbb8b5b8139432f2e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing model.decoder.layers blocks :   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Quantizing layers inside the block:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, GPTQConfig\n",
    "\n",
    "model_id = \"facebook/opt-125m\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "quantization_config = GPTQConfig(bits=4, dataset=\"c4\", tokenizer=tokenizer)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", quantization_config=quantization_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43e1c9e-eee0-40bc-9053-5ff323ead39b",
   "metadata": {},
   "source": [
    "**Load quantized GPTQ model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49e32ec5-c977-4955-89f1-fb6ed38cb17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using `disable_exllama` is deprecated and will be removed in version 4.37. Use `use_exllama` instead and specify the version with `exllama_config`.The value of `use_exllama` will be overwritten by `disable_exllama` passed in `GPTQConfig` or stored in your config file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c3c3a6563e448a99b91bf1e04c1e76d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.16G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py:4371: FutureWarning: `_is_quantized_training_enabled` is going to be deprecated in transformers 4.39.0. Please use `model.hf_quantizer.is_trainable` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1951a878f3d4133942886e91e33537b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"TheBloke/zephyr-7B-beta-GPTQ\",\n",
    "                                             device_map=\"auto\",\n",
    "                                             trust_remote_code=False,\n",
    "                                             revision=\"main\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f38e5a3-1334-410c-855f-d8bc633fdeb0",
   "metadata": {},
   "source": [
    "## AWQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c826c9-a46b-4083-be27-fc315d63c01e",
   "metadata": {},
   "source": [
    "**Load quantized AWQ model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8c5cfcb-2e8f-4fa5-bcab-3b3cd4004c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from awq import AutoAWQForCausalLM\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfd8fc4b-374e-45ff-a465-c72ddac9313a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b301ecb9d6a46d694a1b63a79900940",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1143f2a653948898732e9bb68f50196",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/828 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60a00bb6f432443689f29389d4a7aa25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 13 files:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2059cd602a214292993166a86d6c30cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "quant_config.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8133ca1b787746e78bcce13c27b65afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_results.json:   0%|          | 0.00/195 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a80f05930b54d0a9970c82a32462fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e7ac104a6444028bfcd9ed7ff7a94a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.52k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532ad05e1ccb4ba08d62c784aa5bc0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/32.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67bfcd97e38e4b509bfa21342ea255a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "all_results.json:   0%|          | 0.00/728 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3566a46ec18a44a58239501da3856bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "eval_results.json:   0%|          | 0.00/553 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae88d6180fb14e2fa3f17c1dca52b4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/4.15G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing layers...:   0%|                                                                                                                                                                                            | 0/32 [00:00<?, ?it/s]\u001b[A\n",
      "Replacing layers...:   3%|█████▋                                                                                                                                                                              | 1/32 [00:00<00:08,  3.66it/s]\u001b[A\n",
      "Replacing layers...:   6%|███████████▎                                                                                                                                                                        | 2/32 [00:00<00:07,  4.10it/s]\u001b[A\n",
      "Replacing layers...:   9%|████████████████▉                                                                                                                                                                   | 3/32 [00:00<00:07,  3.99it/s]\u001b[A\n",
      "Replacing layers...:  12%|██████████████████████▌                                                                                                                                                             | 4/32 [00:00<00:06,  4.15it/s]\u001b[A\n",
      "Replacing layers...:  16%|████████████████████████████▏                                                                                                                                                       | 5/32 [00:01<00:06,  4.29it/s]\u001b[A\n",
      "Replacing layers...:  19%|█████████████████████████████████▊                                                                                                                                                  | 6/32 [00:01<00:05,  4.37it/s]\u001b[A\n",
      "Replacing layers...:  22%|███████████████████████████████████████▍                                                                                                                                            | 7/32 [00:01<00:05,  4.41it/s]\u001b[A\n",
      "Replacing layers...:  25%|█████████████████████████████████████████████                                                                                                                                       | 8/32 [00:01<00:05,  4.44it/s]\u001b[A\n",
      "Replacing layers...:  28%|██████████████████████████████████████████████████▋                                                                                                                                 | 9/32 [00:02<00:05,  4.47it/s]\u001b[A\n",
      "Replacing layers...:  31%|███████████████████████████████████████████████████████▉                                                                                                                           | 10/32 [00:02<00:04,  4.49it/s]\u001b[A\n",
      "Replacing layers...:  34%|█████████████████████████████████████████████████████████████▌                                                                                                                     | 11/32 [00:02<00:04,  4.34it/s]\u001b[A\n",
      "Replacing layers...:  38%|███████████████████████████████████████████████████████████████████▏                                                                                                               | 12/32 [00:02<00:04,  4.21it/s]\u001b[A\n",
      "Replacing layers...:  41%|████████████████████████████████████████████████████████████████████████▋                                                                                                          | 13/32 [00:03<00:04,  4.27it/s]\u001b[A\n",
      "Replacing layers...:  44%|██████████████████████████████████████████████████████████████████████████████▎                                                                                                    | 14/32 [00:03<00:04,  4.27it/s]\u001b[A\n",
      "Replacing layers...:  47%|███████████████████████████████████████████████████████████████████████████████████▉                                                                                               | 15/32 [00:03<00:04,  4.21it/s]\u001b[A\n",
      "Replacing layers...:  50%|█████████████████████████████████████████████████████████████████████████████████████████▌                                                                                         | 16/32 [00:03<00:03,  4.30it/s]\u001b[A\n",
      "Replacing layers...:  53%|███████████████████████████████████████████████████████████████████████████████████████████████                                                                                    | 17/32 [00:03<00:03,  4.36it/s]\u001b[A\n",
      "Replacing layers...:  56%|████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                                              | 18/32 [00:04<00:03,  4.40it/s]\u001b[A\n",
      "Replacing layers...:  59%|██████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                                                        | 19/32 [00:04<00:02,  4.43it/s]\u001b[A\n",
      "Replacing layers...:  62%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▉                                                                   | 20/32 [00:04<00:02,  4.45it/s]\u001b[A\n",
      "Replacing layers...:  66%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                                             | 21/32 [00:04<00:02,  4.45it/s]\u001b[A\n",
      "Replacing layers...:  69%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                                                        | 22/32 [00:05<00:02,  4.49it/s]\u001b[A\n",
      "Replacing layers...:  72%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                                                  | 23/32 [00:05<00:02,  4.50it/s]\u001b[A\n",
      "Replacing layers...:  75%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                                            | 24/32 [00:05<00:01,  4.50it/s]\u001b[A\n",
      "Replacing layers...:  78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 25/32 [00:05<00:01,  4.51it/s]\u001b[A\n",
      "Replacing layers...:  81%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                 | 26/32 [00:05<00:01,  4.51it/s]\u001b[A\n",
      "Replacing layers...:  84%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████                            | 27/32 [00:06<00:01,  4.52it/s]\u001b[A\n",
      "Replacing layers...:  88%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▋                      | 28/32 [00:06<00:00,  4.52it/s]\u001b[A\n",
      "Replacing layers...:  91%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                | 29/32 [00:06<00:00,  4.52it/s]\u001b[A\n",
      "Replacing layers...:  94%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊           | 30/32 [00:06<00:00,  4.51it/s]\u001b[A\n",
      "Replacing layers...:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▍     | 31/32 [00:07<00:00,  4.51it/s]\u001b[A\n",
      "Replacing layers...: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:07<00:00,  4.39it/s]\u001b[A\n",
      "Fusing layers...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 32/32 [00:00<00:00, 379.42it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name_or_path = \"TheBloke/zephyr-7B-beta-AWQ\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, trust_remote_code=False)\n",
    "model = AutoAWQForCausalLM.from_quantized(model_name_or_path, fuse_layers=True, trust_remote_code=False, safetensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a96b3c-3167-4574-9f90-88cbd0c06aed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
