{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b500d797-1e52-4435-b8c8-c8f6d83f3bd5",
   "metadata": {},
   "source": [
    "# Creating a langugae model as an embedding model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd068bf9-0dab-49d8-b7a0-7ab567d40a3c",
   "metadata": {},
   "source": [
    "## Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aecd94-6f3a-41cf-99ed-f79b82d63335",
   "metadata": {},
   "source": [
    "**Creating embedding model using pre-trained language model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5f3ad33-8608-42d9-96fd-4e63970a2882",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at klue/roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, models\n",
    "\n",
    "transformer_model = models.Transformer('klue/roberta-base')\n",
    "\n",
    "pooling_layer = models.Pooling(\n",
    "    transformer_model.get_word_embedding_dimension(),\n",
    "    pooling_mode_mean_tokens=True\n",
    ")\n",
    "embedding_model = SentenceTransformer(modules=[transformer_model, pooling_layer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356bab7b-c7f6-49be-96dd-6f144bf08890",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "klue_sts_train = load_dataset('klue', 'sts', split='train')\n",
    "klue_sts_test = load_dataset('klue', 'sts', split='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8df8276e-14d9-46d5-9025-c80a08e65105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'guid': 'klue-sts-v1_train_00000',\n",
       " 'source': 'airbnb-rtt',\n",
       " 'sentence1': '숙소 위치는 찾기 쉽고 일반적인 한국의 반지하 숙소입니다.',\n",
       " 'sentence2': '숙박시설의 위치는 쉽게 찾을 수 있고 한국의 대표적인 반지하 숙박시설입니다.',\n",
       " 'labels': {'label': 3.7, 'real-label': 3.714285714285714, 'binary-label': 1}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_sts_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a31b55d9-dcf5-4e48-b06c-c702a873a74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, validation datasets using training data\n",
    "klue_sts_train = klue_sts_train.train_test_split(test_size=0.1, seed=42)\n",
    "klue_sts_train, klue_sts_eval = klue_sts_train['train'], klue_sts_train['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "012727a4-a32a-44e7-821b-bed84847de10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization label\n",
    "from sentence_transformers import InputExample # format for managing data in Sentence-Transformers\n",
    "\n",
    "# Normalization similarity score to 0 ~ 1 -> IndexExample\n",
    "def prepare_sts_examples(dataset):\n",
    "    examples = []\n",
    "    for data in dataset:\n",
    "        examples.append(\n",
    "            InputExample(\n",
    "                texts=[data['sentence1'], data['sentence2']],\n",
    "                label=data['labels']['label'] / 5.0)\n",
    "        )\n",
    "    return examples\n",
    "\n",
    "train_examples = prepare_sts_examples(klue_sts_train)\n",
    "eval_examples = prepare_sts_examples(klue_sts_eval)\n",
    "test_examples = prepare_sts_examples(klue_sts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3da77f0-5abd-4cd0-8739-d9ba6990ca74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset for training\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "552887f9-0294-4e42-bc76-5b2f64c89f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare evaluation object for validation\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "eval_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(eval_examples)\n",
    "test_evaluator = EmbeddingSimilarityEvaluator.from_input_examples(test_examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f90718d-a696-44d8-9e2f-98bad746edf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36460670798564826"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_evaluator(embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2a2985-1717-4273-8870-5241b0a44822",
   "metadata": {},
   "source": [
    "## Training an embedding model with similar sentence data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c848c656-4b10-4b5e-ade7-7e59e2d06a45",
   "metadata": {},
   "source": [
    "**Training embedding model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "747852ad-e148-4f5d-8dc3-a49fce1195eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c084498c25ac42fe95f3db4bd8b61652",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7aace605ae84e9fa16b858dd9d69eec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a35e9d5ed153439388cf7e1891cfa388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54cf164c6394892884677351b8f6481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddf06cf7dfb4c6d91b403ef4c3ff650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/657 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "num_epochs = 4\n",
    "model_name = 'klue/roberta-base'\n",
    "model_save_path = 'output/training_sts_' + model_name.replace('/', '-')\n",
    "train_loss = losses.CosineSimilarityLoss(model=embedding_model)\n",
    "\n",
    "embedding_model.fit(\n",
    "    train_objectives=[(train_dataloader, train_loss)],\n",
    "    evaluator=eval_evaluator,\n",
    "    epochs=num_epochs,\n",
    "    evaluation_steps=1000,\n",
    "    warmup_steps=100,\n",
    "    output_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e973d5-3aff-440e-91d7-35458645d3ab",
   "metadata": {},
   "source": [
    "**Evaluate trained embedding model performace**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d37d91bd-8d12-4ac5-9cea-dd0f485235d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8891355260276683"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_embedding_model = SentenceTransformer(model_save_path)\n",
    "test_evaluator(trained_embedding_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0830b6e6-5365-48f1-84a4-3110d4a7579d",
   "metadata": {},
   "source": [
    "**Model save in hugging-face hub**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b787a7e-e35f-45c5-b800-dc031d09fb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d21ee31ecc36475ab9564ac3190c04d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Noahyun/klue-roberta-base-klue-sts/commit/6b35913b12e2af8469380986cf8cdf7aa45e1e12', commit_message='Upload folder using huggingface_hub', commit_description='', oid='6b35913b12e2af8469380986cf8cdf7aa45e1e12', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "login(token='input-your-hftokens')\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = 'klue-roberta-base-klue-sts'\n",
    "api.create_repo(repo_id=repo_id)\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=model_save_path,\n",
    "    repo_id=f\"Noahyun/{repo_id}\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baed394e-949d-45e9-8fa7-8905be34a644",
   "metadata": {},
   "source": [
    "# Fine-tuning Embedding Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83bc1b1-3d07-4f00-b5be-5fb4ef6422f3",
   "metadata": {},
   "source": [
    "## Prepare training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338e2980-0c07-447f-bc64-8cfa32cf6b6e",
   "metadata": {},
   "source": [
    "**Dataset check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f98162c-6c15-495e-acdd-df43d3ae28fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "klue_mrc_train = load_dataset('klue', 'mrc', split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8579800-3412-4d2a-b15a-14cd0b14d883",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '제주도 장마 시작 … 중부는 이달 말부터',\n",
       " 'context': '올여름 장마가 17일 제주도에서 시작됐다. 서울 등 중부지방은 예년보다 사나흘 정도 늦은 이달 말께 장마가 시작될 전망이다.17일 기상청에 따르면 제주도 남쪽 먼바다에 있는 장마전선의 영향으로 이날 제주도 산간 및 내륙지역에 호우주의보가 내려지면서 곳곳에 100㎜에 육박하는 많은 비가 내렸다. 제주의 장마는 평년보다 2~3일, 지난해보다는 하루 일찍 시작됐다. 장마는 고온다습한 북태평양 기단과 한랭 습윤한 오호츠크해 기단이 만나 형성되는 장마전선에서 내리는 비를 뜻한다.장마전선은 18일 제주도 먼 남쪽 해상으로 내려갔다가 20일께 다시 북상해 전남 남해안까지 영향을 줄 것으로 보인다. 이에 따라 20~21일 남부지방에도 예년보다 사흘 정도 장마가 일찍 찾아올 전망이다. 그러나 장마전선을 밀어올리는 북태평양 고기압 세력이 약해 서울 등 중부지방은 평년보다 사나흘가량 늦은 이달 말부터 장마가 시작될 것이라는 게 기상청의 설명이다. 장마전선은 이후 한 달가량 한반도 중남부를 오르내리며 곳곳에 비를 뿌릴 전망이다. 최근 30년간 평균치에 따르면 중부지방의 장마 시작일은 6월24~25일이었으며 장마기간은 32일, 강수일수는 17.2일이었다.기상청은 올해 장마기간의 평균 강수량이 350~400㎜로 평년과 비슷하거나 적을 것으로 내다봤다. 브라질 월드컵 한국과 러시아의 경기가 열리는 18일 오전 서울은 대체로 구름이 많이 끼지만 비는 오지 않을 것으로 예상돼 거리 응원에는 지장이 없을 전망이다.',\n",
       " 'news_category': '종합',\n",
       " 'source': 'hankyung',\n",
       " 'guid': 'klue-mrc-v1_train_12759',\n",
       " 'is_impossible': False,\n",
       " 'question_type': 1,\n",
       " 'question': '북태평양 기단과 오호츠크해 기단이 만나 국내에 머무르는 기간은?',\n",
       " 'answers': {'answer_start': [478, 478], 'text': ['한 달가량', '한 달']}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "klue_mrc_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a759589c-3099-4805-aa00-f7d7687a143f",
   "metadata": {},
   "source": [
    "**Load basic embedding model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dff59768-44cf-4b71-9dfb-0d2982e94b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "sentence_model = SentenceTransformer('Noahyun/klue-roberta-base-klue-sts')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05882167-7e7c-416a-95f2-b546f4d748e9",
   "metadata": {},
   "source": [
    "**Preprocess data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d111825-23ca-4553-91dd-80db18b92d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "klue_mrc_train = load_dataset('klue', 'mrc', split='train')\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "\n",
    "df_train = klue_mrc_train.to_pandas()\n",
    "df_test = klue_mrc_test.to_pandas()\n",
    "\n",
    "df_train = df_train[['title', 'question', 'context']]\n",
    "df_test = df_test[['title', 'question', 'context']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34e0cba3-4cb2-48bb-b90f-4436955838f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add irrelevant context\n",
    "\n",
    "def add_ir_context(df):\n",
    "    irrelevant_contexts = []\n",
    "    for idx, row in df.iterrows():\n",
    "        title = row['title']\n",
    "        irrelevant_contexts.append(df.query(f\"title != '{title}'\").sample(n=1)['context'].values[0])\n",
    "    df['irrelevant_context'] = irrelevant_contexts\n",
    "    return df\n",
    "\n",
    "df_train_ir = add_ir_context(df_train)\n",
    "df_test_ir = add_ir_context(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "271ac3eb-adc9-4d0e-afb6-72d957442e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make data for evaluation performance\n",
    "\n",
    "from sentence_transformers import InputExample\n",
    "\n",
    "examples = []\n",
    "for idx, row in df_test_ir.iterrows():\n",
    "    examples.append(\n",
    "        InputExample(texts=[row['question'], row['context']], label=1)\n",
    "    )\n",
    "    examples.append(\n",
    "        InputExample(texts=[row['question'], row['irrelevant_context']], label=0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70d375-b040-471c-aef3-b8a7b5cec1d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "\n",
    "from sentence_transformers.evaluation import EmbeddingSimilarityEvaluator\n",
    "\n",
    "evaluator = EmbeddingSimilarityEvaluator.from_input_examples(\n",
    "    examples\n",
    ")\n",
    "evaluator(sentence_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c952785c-fb51-4800-b0af-08955873bf21",
   "metadata": {},
   "source": [
    "## Fine-tuning using MNR loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4b0836-00dd-4828-89e4-54a331a416e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "train_samples = []\n",
    "for idx, row in df_train_ir.iterrows():\n",
    "    train_samples.append(InputExample(texts=[row['question'], row['context']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca4ca0f-e13a-47f5-a469-a3724b5a0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates\n",
    "from sentence_transformers import datasets\n",
    "\n",
    "batch_size = 16\n",
    "loader = datasets.NoDuplicatesDataLoader(train_samples, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7702165e-3a9d-4f67-ae9b-f1b88802d929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNR loss\n",
    "from sentence_transformers import losses\n",
    "\n",
    "loss = losses.MultipleNegativesRankingLoss(sentence_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0172628-478f-4d70-8e8e-d7d0771b369a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da591e0f029d4eaca97e34889fbe2abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6df7c7744a74e2aa5b0daf53f0e5c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1097 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fine-tuning\n",
    "epochs = 1\n",
    "save_path = './klue_mrc_mnr'\n",
    "\n",
    "sentence_model.fit(\n",
    "    train_objectives=[(loader, loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=100,\n",
    "    output_path=save_path,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ebb9026d-fe02-4c01-a4e2-74270bbf8b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8594708084199976"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "evaluator(sentence_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "319d8438-5f68-4f2d-bd59-8653e9f1f435",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b55fc34bc147d480d945be7eab66a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Noahyun/klue-roberta-base-klue-sts-mrc/commit/deb9069a385962e8bcce2645804ba99c24a8a08d', commit_message='Upload folder using huggingface_hub', commit_description='', oid='deb9069a385962e8bcce2645804ba99c24a8a08d', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = 'klue-roberta-base-klue-sts-mrc'\n",
    "api.create_repo(repo_id=repo_id)\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=save_path,\n",
    "    repo_id=f\"Noahyun/{repo_id}\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d09576-f600-4570-8b75-357e626ed213",
   "metadata": {},
   "source": [
    "# Reorder the rankings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe21f8f-4d01-4a79-9ae7-79ff57f1a1b7",
   "metadata": {},
   "source": [
    "**cross-encoder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0828d949-34d8-4cbb-b9fd-0818f4bf0f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at klue/roberta-small and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import CrossEncoder\n",
    "\n",
    "cross_model = CrossEncoder('klue/roberta-small', num_labels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5020f66e-765b-41cf-acc1-ec2e77c70c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation cross encoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CECorrelationEvaluator\n",
    "\n",
    "ce_evaluator = CECorrelationEvaluator.from_input_examples(examples)\n",
    "ce_evaluator(cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "de5c3199-f641-4423-b439-0d3169a30a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset\n",
    "train_samples = []\n",
    "for idx, row in df_train_ir.iterrows():\n",
    "    train_samples.append(InputExample(texts=[row['question'], row['context']], label=1))\n",
    "    train_samples.append(InputExample(texts=[row['question'], row['irrelevant_context']], label=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "620a7fc1-070f-474f-8a6a-93bb81a2837f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6f946e7f614b1e9b2f333b9a1e8cb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f8e6d4b65d453b9fdffd8b704234e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/2195 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# train cross encoder\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_batch_size = 16\n",
    "num_epochs = 1\n",
    "model_save_path = 'output/training_mrc'\n",
    "\n",
    "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=train_batch_size)\n",
    "\n",
    "cross_model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    epochs=num_epochs,\n",
    "    warmup_steps=100,\n",
    "    output_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29683ee1-7a88-4155-b538-a0ea47f54558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8648947632389092"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate\n",
    "ce_evaluator(cross_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97eb44e3-89cc-4322-911a-d30150960ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token has not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Noahyun/klue-roberta-small-cross-encoder/commit/de67dae4310034eb397a934e651a5ca1d97c4eac', commit_message='Upload folder using huggingface_hub', commit_description='', oid='de67dae4310034eb397a934e651a5ca1d97c4eac', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "login(token='input your hftokens')\n",
    "api = HfApi()\n",
    "\n",
    "repo_id = 'klue-roberta-small-cross-encoder'\n",
    "api.create_repo(repo_id=repo_id)\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=model_save_path,\n",
    "    repo_id=f\"Noahyun/{repo_id}\",\n",
    "    repo_type=\"model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d1612c7-5755-4f32-a45a-3518585c3a03",
   "metadata": {},
   "source": [
    "# RAG Implementation with bi-encoder and cross-encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9558edc5-44bf-4283-9d47-9f0c443c300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset sampling for test\n",
    "from datasets import load_dataset\n",
    "\n",
    "klue_mrc_test = load_dataset('klue', 'mrc', split='validation')\n",
    "klue_mrc_test = klue_mrc_test.train_test_split(test_size=1000, seed=42)['test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d0ba240-2cb8-4e3d-be62-d84e0153c228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement function to store and retrieve embeddings\n",
    "import faiss\n",
    "\n",
    "def make_embedding_index(sentence_model, corpus):\n",
    "    embeddings = sentence_model.encode(corpus)\n",
    "    index = faiss.IndexFlatL2(embeddings.shape[1])\n",
    "    index.add(embeddings)\n",
    "    return index\n",
    "\n",
    "def find_embedding_top_k(query, sentence_model, index, k):\n",
    "    embedding = sentence_model.encode([query])\n",
    "    distances, indices = index.search(embedding, k)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "195398aa-ab70-45ea-861d-1e8913687e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rerank orders\n",
    "def make_question_context_pairs(question_idx, indices):\n",
    "    return [[klue_mrc_test['question'][question_idx], klue_mrc_test['context'][idx]] for idx in indices]\n",
    "\n",
    "def rerank_top_k(cross_model, question_idx, indices, k):\n",
    "    input_examples = make_question_context_pairs(question_idx, indices)\n",
    "    relevance_scores = cross_model.predict(input_examples)\n",
    "    reranked_indices = indices[np.argsort(relevance_scores)[::-1]]\n",
    "    return reranked_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ae81e61-d202-4248-ac7d-b17ed0563a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric: hit rate\n",
    "import time\n",
    "\n",
    "def evaluate_hit_rate(datasets, embedding_model, index, k=10):\n",
    "    start_time = time.time()\n",
    "    predictions = []\n",
    "    for question in datasets['question']:\n",
    "        predictions.append(find_embedding_top_k(question, embedding_model, index, k)[0])\n",
    "    total_prediction_count = len(predictions)\n",
    "    hit_count = 0\n",
    "    questions = datasets['question']\n",
    "    context = datasets['context']\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        for pred in prediction:\n",
    "            if context[pred] == context[idx]:\n",
    "                hit_count += 1\n",
    "                break\n",
    "\n",
    "    end_time = time.time()\n",
    "    return hit_count / total_prediction_count, end_time - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bd860b-1f42-45fb-9ac0-aa27abd4ae16",
   "metadata": {},
   "source": [
    "## Retrieval using base embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98e01107-f361-4b48-985b-055a7b48ba3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.87, 3.5601565837860107)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "base_embedding_model = SentenceTransformer('Noahyun/klue-roberta-base-klue-sts')\n",
    "base_index = make_embedding_index(base_embedding_model, klue_mrc_test['context'])\n",
    "\n",
    "evaluate_hit_rate(klue_mrc_test, base_embedding_model, base_index, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafa67ee-dc4b-4f66-8fb4-e4bdb52061be",
   "metadata": {},
   "source": [
    "## Retrieval using fine-tuned embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902e521d-0af5-4e99-b46e-a1c7c534298c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d413eb381df64b64a07ff0deec00965c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "038d5f5c639c48dfbac4d9668bcad82b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/171 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "600113bb32c54245a6081e91a7c0e159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/3.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec83f09d9faa46c9bfbfac42108194f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cccad5243a0b4902ad53a6fba0b850d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/761 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d18a8cecc2b8456fa955a7465e0c5227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/442M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ed7aaeda9c4b46804c67bf7fc62921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.47k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55909e9fd8b340e5aac5b335ae3a6317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/248k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34525bf0633b42cba3f3cb4ac75fb4cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/752k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a91eebe559424960bd973fc9b3b3bbfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/971 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ce8e6cfb1e4e839c3beba5ec19ed1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(0.946, 3.6130285263061523)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finetuned_embedding_model = SentenceTransformer('Noahyun/klue-roberta-base-klue-sts-mrc')\n",
    "finetuned_index = make_embedding_index(finetuned_embedding_model, klue_mrc_test['context'])\n",
    "\n",
    "evaluate_hit_rate(klue_mrc_test, finetuned_embedding_model, finetuned_index, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f3ef754-27ad-446f-83f0-01dbdf6904fe",
   "metadata": {},
   "source": [
    "## Retrieval using combination with fine-tuned embedding model and cross encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c14e4b3d-5665-4802-940e-20f214250d27",
   "metadata": {},
   "source": [
    "**Evaluate metric including order rerank**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f2f9a27-89d5-4810-8ea1-3512518f4eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "def evaluate_hit_rate_with_rerank(datasets, embedding_model, cross_model, index, bi_k=30, cross_k=10):\n",
    "    start_time = time.time()\n",
    "    predictions = []\n",
    "    for question_idx, question in enumerate(tqdm(datasets['question'])):\n",
    "        indices = find_embedding_top_k(question, embedding_model, index, bi_k)[0]\n",
    "        predictions.append(rerank_top_k(cross_model, question_idx, indices, k=cross_k))\n",
    "    total_prediction_count = len(predictions)\n",
    "    hit_count = 0\n",
    "    questions = datasets['question']\n",
    "    contexts = datasets['context']\n",
    "    for idx, prediction in enumerate(predictions):\n",
    "        for pred in prediction:\n",
    "            if contexts[pred] == contexts[idx]:\n",
    "                hit_count += 1\n",
    "                break\n",
    "    end_time = time.time()\n",
    "    return hit_count / total_prediction_count, end_time - start_time, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecefc290-d216-4281-8cda-a631a3c61748",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_model = SentenceTransformer('shangrilar/klue-roberta-small-cross-encoder')\n",
    "\n",
    "hit_rate, cosumed_time, predictions = evaluate_hit_rate_with_rerank(klue_mrc_test, finetuned_embedding_model, cross_model, finetuned_index)\n",
    "hit_rate, cosumed_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71636821-6c3b-4f57-9146-4e4a6ab8010c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
