{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b95445f4-1f6e-412c-af8b-bbde731c75ef",
   "metadata": {},
   "source": [
    "# LLM Serving Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7895f164-29b1-431d-a98f-0fac4aefc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vllm==0.4.1 -qqq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ed3715-52ef-4708-af12-e1108603aada",
   "metadata": {},
   "source": [
    "## Offline serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f47ac1-0653-48d4-a4bf-93c18a7dae48",
   "metadata": {},
   "source": [
    "**Prepare dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "212fc742-d1ec-46cc-b6fd-4b4bb13fe757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "def make_prompt(ddl, question, query=''):\n",
    "    prompt = f\"\"\"당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\n",
    "\n",
    "### DDL:\n",
    "{ddl}\n",
    "\n",
    "### Question:\n",
    "{question}\n",
    "\n",
    "### SQL:\n",
    "{query}\"\"\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25cf7fc8-3756-4c84-aa59-6ffb322160ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"shangrilar/ko_text2sql\", \"origin\")['test']\n",
    "dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e17177fe-4fde-4a74-858a-b91bcb84302d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>각 보상 아이템별로 보상 경험치의 합을 구해줘</td>\n",
       "      <td>SELECT reward_items, SUM(reward_experience) AS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE players (\\n  player_id INT PRIMAR...</td>\n",
       "      <td>사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.</td>\n",
       "      <td>SELECT COUNT(*) FROM players WHERE username LI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?</td>\n",
       "      <td>SELECT q.name, q.reward_experience FROM quests...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가</td>\n",
       "      <td>SELECT name FROM characters WHERE experience &gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.</td>\n",
       "      <td>SELECT C.name, ST.skill_name FROM characters A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>캐릭터가 완료한 퀘스트 중 보상 경험치가 100 이상 200 이하인 퀘스트의 이름과...</td>\n",
       "      <td>SELECT q.name, q.reward_items FROM quests AS q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>경험이 1000에서 2000 사이인 캐릭터들의 이름, 레벨, 경험치, 아이템 이름 ...</td>\n",
       "      <td>SELECT c.name, c.level, c.experience, i.item_n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE npcs (\\n  npc_id INT PRIMARY KEY ...</td>\n",
       "      <td>각 역할별로 npc의 총 수를 알려주세요.</td>\n",
       "      <td>SELECT role, COUNT(npc_id) FROM npcs GROUP BY ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>장비가 장착된 상태인 캐릭터의 플레이어 ID와 아이템 이름을 나열하십시오.</td>\n",
       "      <td>SELECT T1.player_id, T2.item_name FROM charact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>인벤토리 아이템의 이름과 수량, 해당 아이템을 소유한 캐릭터의 클래스를 보여주세요.</td>\n",
       "      <td>SELECT T2.item_name, T2.quantity, T1.character...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     db_id                                            context  \\\n",
       "0        1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "1        1  CREATE TABLE players (\\n  player_id INT PRIMAR...   \n",
       "2        1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "3        1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "4        1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "..     ...                                                ...   \n",
       "107      1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "108      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "109      1  CREATE TABLE npcs (\\n  npc_id INT PRIMARY KEY ...   \n",
       "110      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "111      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "\n",
       "                                              question  \\\n",
       "0                            각 보상 아이템별로 보상 경험치의 합을 구해줘   \n",
       "1               사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.   \n",
       "2             퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?   \n",
       "3             경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가   \n",
       "4       레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.   \n",
       "..                                                 ...   \n",
       "107  캐릭터가 완료한 퀘스트 중 보상 경험치가 100 이상 200 이하인 퀘스트의 이름과...   \n",
       "108  경험이 1000에서 2000 사이인 캐릭터들의 이름, 레벨, 경험치, 아이템 이름 ...   \n",
       "109                            각 역할별로 npc의 총 수를 알려주세요.   \n",
       "110          장비가 장착된 상태인 캐릭터의 플레이어 ID와 아이템 이름을 나열하십시오.   \n",
       "111     인벤토리 아이템의 이름과 수량, 해당 아이템을 소유한 캐릭터의 클래스를 보여주세요.   \n",
       "\n",
       "                                                answer  \n",
       "0    SELECT reward_items, SUM(reward_experience) AS...  \n",
       "1    SELECT COUNT(*) FROM players WHERE username LI...  \n",
       "2    SELECT q.name, q.reward_experience FROM quests...  \n",
       "3    SELECT name FROM characters WHERE experience >...  \n",
       "4    SELECT C.name, ST.skill_name FROM characters A...  \n",
       "..                                                 ...  \n",
       "107  SELECT q.name, q.reward_items FROM quests AS q...  \n",
       "108  SELECT c.name, c.level, c.experience, i.item_n...  \n",
       "109  SELECT role, COUNT(npc_id) FROM npcs GROUP BY ...  \n",
       "110  SELECT T1.player_id, T2.item_name FROM charact...  \n",
       "111  SELECT T2.item_name, T2.quantity, T1.character...  \n",
       "\n",
       "[112 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23c63bdf-0589-4119-b7a9-ba557b8aed66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('CREATE TABLE quests (\\n  quest_id INT PRIMARY KEY AUTO_INCREMENT,\\n  name VARCHAR(255) NOT NULL,\\n  description TEXT,\\n  reward_experience INT NOT NULL,\\n  reward_items VARCHAR(255)\\n);',\n",
       " '각 보상 아이템별로 보상 경험치의 합을 구해줘')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['context'][0], dataset['question'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ee518b3-f23d-472e-a1a9-cf80c6841d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in dataset.iterrows():\n",
    "    prompt = make_prompt(row['context'], row['question'])\n",
    "    dataset.loc[idx, 'prompt'] = prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d48f5099-8295-442f-9fc2-fc6a22f16188",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>db_id</th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>각 보상 아이템별로 보상 경험치의 합을 구해줘</td>\n",
       "      <td>SELECT reward_items, SUM(reward_experience) AS...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE players (\\n  player_id INT PRIMAR...</td>\n",
       "      <td>사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.</td>\n",
       "      <td>SELECT COUNT(*) FROM players WHERE username LI...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?</td>\n",
       "      <td>SELECT q.name, q.reward_experience FROM quests...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가</td>\n",
       "      <td>SELECT name FROM characters WHERE experience &gt;...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.</td>\n",
       "      <td>SELECT C.name, ST.skill_name FROM characters A...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE quests (\\n  quest_id INT PRIMARY ...</td>\n",
       "      <td>캐릭터가 완료한 퀘스트 중 보상 경험치가 100 이상 200 이하인 퀘스트의 이름과...</td>\n",
       "      <td>SELECT q.name, q.reward_items FROM quests AS q...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>경험이 1000에서 2000 사이인 캐릭터들의 이름, 레벨, 경험치, 아이템 이름 ...</td>\n",
       "      <td>SELECT c.name, c.level, c.experience, i.item_n...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE npcs (\\n  npc_id INT PRIMARY KEY ...</td>\n",
       "      <td>각 역할별로 npc의 총 수를 알려주세요.</td>\n",
       "      <td>SELECT role, COUNT(npc_id) FROM npcs GROUP BY ...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>장비가 장착된 상태인 캐릭터의 플레이어 ID와 아이템 이름을 나열하십시오.</td>\n",
       "      <td>SELECT T1.player_id, T2.item_name FROM charact...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>CREATE TABLE characters (\\n  character_id INT ...</td>\n",
       "      <td>인벤토리 아이템의 이름과 수량, 해당 아이템을 소유한 캐릭터의 클래스를 보여주세요.</td>\n",
       "      <td>SELECT T2.item_name, T2.quantity, T1.character...</td>\n",
       "      <td>당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>112 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     db_id                                            context  \\\n",
       "0        1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "1        1  CREATE TABLE players (\\n  player_id INT PRIMAR...   \n",
       "2        1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "3        1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "4        1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "..     ...                                                ...   \n",
       "107      1  CREATE TABLE quests (\\n  quest_id INT PRIMARY ...   \n",
       "108      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "109      1  CREATE TABLE npcs (\\n  npc_id INT PRIMARY KEY ...   \n",
       "110      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "111      1  CREATE TABLE characters (\\n  character_id INT ...   \n",
       "\n",
       "                                              question  \\\n",
       "0                            각 보상 아이템별로 보상 경험치의 합을 구해줘   \n",
       "1               사용자 이름에 'admin'이 포함되어 있는 계정의 수를 알려주세요.   \n",
       "2             퀘스트 진행 상황이 100%인 퀘스트의 이름과 보상 경험치는 얼마인가요?   \n",
       "3             경험이 5000000 이상이거나 직업이 전사인 캐릭터들의 이름은 무엇인가   \n",
       "4       레벨이 20 이상인 플레이어의 캐릭터 이름과 해당 캐릭터의 스킬 이름을 알아보세요.   \n",
       "..                                                 ...   \n",
       "107  캐릭터가 완료한 퀘스트 중 보상 경험치가 100 이상 200 이하인 퀘스트의 이름과...   \n",
       "108  경험이 1000에서 2000 사이인 캐릭터들의 이름, 레벨, 경험치, 아이템 이름 ...   \n",
       "109                            각 역할별로 npc의 총 수를 알려주세요.   \n",
       "110          장비가 장착된 상태인 캐릭터의 플레이어 ID와 아이템 이름을 나열하십시오.   \n",
       "111     인벤토리 아이템의 이름과 수량, 해당 아이템을 소유한 캐릭터의 클래스를 보여주세요.   \n",
       "\n",
       "                                                answer  \\\n",
       "0    SELECT reward_items, SUM(reward_experience) AS...   \n",
       "1    SELECT COUNT(*) FROM players WHERE username LI...   \n",
       "2    SELECT q.name, q.reward_experience FROM quests...   \n",
       "3    SELECT name FROM characters WHERE experience >...   \n",
       "4    SELECT C.name, ST.skill_name FROM characters A...   \n",
       "..                                                 ...   \n",
       "107  SELECT q.name, q.reward_items FROM quests AS q...   \n",
       "108  SELECT c.name, c.level, c.experience, i.item_n...   \n",
       "109  SELECT role, COUNT(npc_id) FROM npcs GROUP BY ...   \n",
       "110  SELECT T1.player_id, T2.item_name FROM charact...   \n",
       "111  SELECT T2.item_name, T2.quantity, T1.character...   \n",
       "\n",
       "                                                prompt  \n",
       "0    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "1    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "2    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "3    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "4    당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "..                                                 ...  \n",
       "107  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "108  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "109  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "110  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "111  당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question...  \n",
       "\n",
       "[112 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be84a39-f704-4737-a125-e73538f2d17d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'당신은 SQL을 생성하는 SQL 봇입니다. DDL의 테이블을 활용한 Question을 해결할 수 있는 SQL 쿼리를 생성하세요.\\n\\n### DDL:\\nCREATE TABLE quests (\\n  quest_id INT PRIMARY KEY AUTO_INCREMENT,\\n  name VARCHAR(255) NOT NULL,\\n  description TEXT,\\n  reward_experience INT NOT NULL,\\n  reward_items VARCHAR(255)\\n);\\n\\n### Question:\\n각 보상 아이템별로 보상 경험치의 합을 구해줘\\n\\n### SQL:\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['prompt'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5b8238-0104-42b5-92a1-0401ce1b3c86",
   "metadata": {},
   "source": [
    "**Set pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a743c621-ddb4-4071-9d4a-3f852eceedc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-19 03:56:13.973338: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-19 03:56:14.066764: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-19 03:56:14.070583: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-19 03:56:14.070594: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2024-11-19 03:56:14.091048: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-19 03:56:14.673980: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-19 03:56:14.674029: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2024-11-19 03:56:14.674035: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dddef7bf-e352-40bb-99d5-f5ec985fabe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b1dc8feb12f4024976e087f1551b528",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/694 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c0d01df8db4ec1974016ded5c80c22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2315afb7d554f96a371fb928c3dc81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c794af4e91a4e6db84f7da52ea800e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00003.safetensors:   0%|          | 0.00/4.96G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c365b8b8077a406a9cc14e2ca7f9615d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00003.safetensors:   0%|          | 0.00/4.93G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3977ce18814896a6fb37d3eb984433",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00003.safetensors:   0%|          | 0.00/2.46G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "467b9305ad174250b67fab537f897363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3688305e6164fa6a8ce9447b02ebf03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be23d4e975e34f1ea5646e826f282a89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/9.74k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f9750cd07eb4168a768b2890a57abc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/4.28M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00df984bccfb440cbf91f47ff1a65bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/467 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"shangrilar/yi-ko-6b-text2sql\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, device_map=\"auto\", load_in_4bit=True, bnb_4bit_compute_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "hf_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f71260-f322-4129-80c4-261396a70449",
   "metadata": {},
   "source": [
    "**Check inference time according to batch size**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af48e1ca-2337-4d09-a861-280fed358d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b48c09b4-ec9e-4d14-80b6-0b3327147c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 163.83604764938354\n",
      "2: 131.64016199111938\n",
      "4: 87.19056105613708\n",
      "8: 56.38193464279175\n",
      "16: 33.51246905326843\n",
      "32: 23.756344318389893\n"
     ]
    }
   ],
   "source": [
    "for batch_size in [1, 2, 4, 8, 16, 32]:\n",
    "    start_time = time.time()\n",
    "    hf_pipeline(dataset['prompt'].tolist(), max_new_tokens=128, batch_size=batch_size)\n",
    "    print(f\"{batch_size}: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6838235b-d75b-4e2c-88d6-6973e75af9d6",
   "metadata": {},
   "source": [
    "**Load vLLM model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0cecfa0-058c-49c9-ad44-31491f2e1b32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vllm import LLM, SamplingParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94bb3e23-5e7e-4cf3-87a6-bf9c26c81563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-19 04:25:11 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='shangrilar/yi-ko-6b-text2sql', speculative_config=None, tokenizer='shangrilar/yi-ko-6b-text2sql', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-19 04:25:11 utils.py:608] Found nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 11-19 04:25:12 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 11-19 04:25:12 selector.py:33] Using XFormers backend.\n",
      "INFO 11-19 04:25:13 weight_utils.py:193] Using model weights format ['*.safetensors']\n",
      "INFO 11-19 04:25:16 model_runner.py:173] Loading model weights took 11.5127 GB\n",
      "INFO 11-19 04:25:17 gpu_executor.py:119] # GPU blocks: 9049, # CPU blocks: 4096\n",
      "INFO 11-19 04:25:18 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-19 04:25:18 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-19 04:25:24 model_runner.py:1057] Graph capturing finished in 6 secs.\n"
     ]
    }
   ],
   "source": [
    "model_id = \"shangrilar/yi-ko-6b-text2sql\"\n",
    "\n",
    "llm = LLM(model=model_id, dtype=torch.float16, max_model_len=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c649769-5178-473a-9b01-5f77be205b3f",
   "metadata": {},
   "source": [
    "**Measuring offline inference time using vLLM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5beb059-01ff-4638-855c-7a19e03558b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [01:02<00:00,  1.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 62.1559956073761\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:34<00:00,  3.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2: 34.31376624107361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:19<00:00,  5.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4: 19.977014541625977\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:11<00:00,  9.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8: 11.73049283027649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:07<00:00, 14.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16: 7.821612358093262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processed prompts: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 112/112 [00:06<00:00, 18.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32: 6.1246702671051025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# max_num_seqs : Control the number of input data to perform inference on simultaneously\n",
    "for max_num_seqs in [1, 2, 4, 8, 16, 32]:\n",
    "    start_time = time.time()\n",
    "    llm.llm_engine.scheduler_config.max_num_seqs = max_num_seqs\n",
    "    sampling_params = SamplingParams(temperature=1, top_p=1, max_tokens=128)\n",
    "    output = llm.generate(dataset['prompt'].to_list(), sampling_params)\n",
    "    print(f\"{max_num_seqs}: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a5787e-f21f-4ca0-9bd9-038d6d82be4d",
   "metadata": {},
   "source": [
    "## Online serving"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43092c26-5434-49cb-844f-64aeff90c021",
   "metadata": {},
   "source": [
    "**Running a vLLM API server for online serving**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03e14a0a-d4e0-413f-9654-b2223c86cbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-19 04:34:02 api_server.py:151] vLLM API server version 0.4.1\n",
      "INFO 11-19 04:34:02 api_server.py:152] args: Namespace(host='127.0.0.1', port=8890, uvicorn_log_level='info', allow_credentials=False, allowed_origins=['*'], allowed_methods=['*'], allowed_headers=['*'], api_key=None, served_model_name=None, lora_modules=None, chat_template=None, response_role='assistant', ssl_keyfile=None, ssl_certfile=None, ssl_ca_certs=None, ssl_cert_reqs=0, root_path=None, middleware=[], model='shangrilar/yi-ko-6b-text2sql', tokenizer=None, skip_tokenizer_init=False, revision=None, code_revision=None, tokenizer_revision=None, tokenizer_mode='auto', trust_remote_code=False, download_dir=None, load_format='auto', dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, max_model_len=1024, guided_decoding_backend='outlines', worker_use_ray=False, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, ray_workers_use_nsight=False, block_size=16, enable_prefix_caching=False, use_v2_block_manager=False, num_lookahead_slots=0, seed=0, swap_space=4, gpu_memory_utilization=0.9, num_gpu_blocks_override=None, max_num_batched_tokens=None, max_num_seqs=256, max_logprobs=5, disable_log_stats=False, quantization=None, enforce_eager=False, max_context_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, enable_lora=False, max_loras=1, max_lora_rank=16, lora_extra_vocab_size=256, lora_dtype='auto', max_cpu_loras=None, device='auto', image_input_type=None, image_token_id=None, image_input_shape=None, image_feature_size=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, speculative_model=None, num_speculative_tokens=None, speculative_max_model_len=None, model_loader_extra_config=None, engine_use_ray=False, disable_log_requests=False, max_log_len=None)\n",
      "INFO 11-19 04:34:02 llm_engine.py:98] Initializing an LLM engine (v0.4.1) with config: model='shangrilar/yi-ko-6b-text2sql', speculative_config=None, tokenizer='shangrilar/yi-ko-6b-text2sql', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=auto, tensor_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), seed=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-19 04:34:02 utils.py:608] Found nccl from library /root/.config/vllm/nccl/cu12/libnccl.so.2.18.1\n",
      "INFO 11-19 04:34:03 selector.py:77] Cannot use FlashAttention backend because the flash_attn package is not found. Please install it for better performance.\n",
      "INFO 11-19 04:34:03 selector.py:33] Using XFormers backend.\n",
      "INFO 11-19 04:34:04 weight_utils.py:193] Using model weights format ['*.safetensors']\n",
      "INFO 11-19 04:34:07 model_runner.py:173] Loading model weights took 11.5127 GB\n",
      "INFO 11-19 04:34:07 gpu_executor.py:119] # GPU blocks: 9049, # CPU blocks: 4096\n",
      "INFO 11-19 04:34:09 model_runner.py:976] Capturing the model for CUDA graphs. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI.\n",
      "INFO 11-19 04:34:09 model_runner.py:980] CUDA graphs can take additional 1~3 GiB memory per GPU. If you are running out of memory, consider decreasing `gpu_memory_utilization` or enforcing eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n",
      "INFO 11-19 04:34:14 model_runner.py:1057] Graph capturing finished in 5 secs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING 11-19 04:34:14 serving_chat.py:347] No chat template provided. Chat API will not work.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "INFO:     Started server process [18633]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8890 (Press CTRL+C to quit)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 11-19 04:34:24 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:34:34 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:34:44 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:34:54 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:35:04 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:35:14 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:35:24 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:35:34 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "INFO 11-19 04:35:44 metrics.py:229] Avg prompt throughput: 0.0 tokens/s, Avg generation throughput: 0.0 tokens/s, Running: 0 reqs, Swapped: 0 reqs, Pending: 0 reqs, GPU KV cache usage: 0.0%, CPU KV cache usage: 0.0%\n",
      "Process is interrupted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [18633]\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "nohup python3 -m vllm.entrypoints.openai.api_server \\\n",
    "--model shangrilar/yi-ko-6b-text2sql --host 127.0.0.1 --port 8890 --max-model-len 1024 &"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044d6855-7c6b-48e1-847a-3f11dd8087cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:8888/v1/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0950ea08-127d-4407-bb6c-caa04d476a2f",
   "metadata": {},
   "source": [
    "**API request**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f634a7be-530e-459b-bd38-8cd539cfd62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79d0394-bc8e-49d3-aad1-b8c048e57d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = json.dumps(\n",
    "    {\"model\": \"shangrilar/yi-ko-6b-text2sql\",\n",
    "     \"prompt\": dataset.loc[0, \"prompt\"],\n",
    "     \"max_tokens\": 128,\n",
    "     \"temperature\": 1}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b40521-8533-48fc-8b81-5e0054f74228",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl http://localhost:8888/v1/completions \\\n",
    "    -H \"Content-Type: application/json\" \\\n",
    "    -d '{json_data}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c052ddf9-dac5-4780-8cd4-abc157e011ec",
   "metadata": {},
   "source": [
    "**OpenAI 클라이언트를 사용한 API 요청**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35a23bea-1c0b-44b4-bd37-2489f9ad4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012386ab-fbff-4a05-a95c-595c32c3a1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai_api_key = \"EMPTY\"\n",
    "openai_api_base = \"http://localhost:8888/v1\"\n",
    "client = OpenAI(\n",
    "    # api_key=openai_api_key,\n",
    "    base_url=openai_api_base,\n",
    ")\n",
    "completion = client.completions.create(model=\"shangrilar/yi-ko-6b-text2sql\", prompt=dataset.loc[0, 'prompt'], max_tokens=128)\n",
    "print(\"생성 결과:\", completion.choices[0].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd64d8fd-b7d8-4114-9266-d1b754540c1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
